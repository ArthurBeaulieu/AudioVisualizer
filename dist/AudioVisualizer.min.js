/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ({

/***/ "./src/js/AudioVisualizer.js":
/*!***********************************!*\
  !*** ./src/js/AudioVisualizer.js ***!
  \***********************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _components_FrequencyBars_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./components/FrequencyBars.js */ "./src/js/components/FrequencyBars.js");
/* harmony import */ var _components_FrequencyCircle_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./components/FrequencyCircle.js */ "./src/js/components/FrequencyCircle.js");
/* harmony import */ var _components_Oscilloscope_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./components/Oscilloscope.js */ "./src/js/components/Oscilloscope.js");
/* harmony import */ var _components_PeakMeter_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./components/PeakMeter.js */ "./src/js/components/PeakMeter.js");
/* harmony import */ var _components_Spectrum_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./components/Spectrum.js */ "./src/js/components/Spectrum.js");
/* harmony import */ var _components_Timeline_js__WEBPACK_IMPORTED_MODULE_5__ = __webpack_require__(/*! ./components/Timeline.js */ "./src/js/components/Timeline.js");
/* harmony import */ var _components_WaveformProgress_js__WEBPACK_IMPORTED_MODULE_6__ = __webpack_require__(/*! ./components/WaveformProgress.js */ "./src/js/components/WaveformProgress.js");







'use strict';


/* AudioVisualizer version 0.9.3 */
const AudioVisualizerVersion = '0.9.3';
window.AudioContext = window.AudioContext || window.webkitAudioContext;


class AudioVisualizer {


  /** @summary AudioVisualizer factory class to build all supported visualisation
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>This factory will return an <code>AudioVisualizer</code> component. It is
   * automatically rendered, and will also be automatically linked to given audio source. No further manipulation
   * are required (except destroy when done using) on runtime.<br><br>Each components have shared properties,
   * and unique properties, as described in components class themselves. Refer to the components documentation for
   * specific options.<br><br>Multi visualisation can have an impact on CPU load that mostly depends on client configuration.
   * Keep that in mind if you develop your project with a battle station. When done using a component, please call its
   * <code>destroy</code> method to remove listeners and audio processing to avoid memory leaks in your app.</blockquote>
   * @param {object} options - The audio visualisation definition
   * @param {string} options.type - The visualisation type, can be <code>bars</code>/<code>circle</code>/<code>oscilloscope</code>/<code>peakmeter</code>/<code>spectrum</code>/<code>timeline</code>/<code>waveform</code>
   * @param {object} options.player - A DOM audio player to be the audio source for processing
   * @param {object} options.renderTo - A DOM element to render the visualisation in. It will automatically scale content to this element's dimension
   * @param {object} [options.audioContext=null] - A WebAudioAPI audio context to chain the processing nodes in your audio routing.
   * @param {object} [options.inputNode=null] - The WebAudioAPI audio node to be the audio source for processing, You must provide an audioContext
   * @param {number} [options.fftSize=1024] - The FFT size to use in processing, must be a power of 2. High values cost more CPU
   * @returns {object|null} - The custom visualisation component according to given options, <code>null</code> for unknown type */
  constructor(options) {
    if (options.type === 'bars') {
      return new _components_FrequencyBars_js__WEBPACK_IMPORTED_MODULE_0__["default"](options);
    } else if (options.type === 'circle') {
      return new _components_FrequencyCircle_js__WEBPACK_IMPORTED_MODULE_1__["default"](options);
    } else if (options.type === 'oscilloscope') {
      return new _components_Oscilloscope_js__WEBPACK_IMPORTED_MODULE_2__["default"](options);
    } else if (options.type === 'peakmeter') {
      return new _components_PeakMeter_js__WEBPACK_IMPORTED_MODULE_3__["default"](options);
    } else if (options.type === 'spectrum') {
      return new _components_Spectrum_js__WEBPACK_IMPORTED_MODULE_4__["default"](options);
    } else if (options.type === 'timeline') {
      return new _components_Timeline_js__WEBPACK_IMPORTED_MODULE_5__["default"](options);
    } else if (options.type === 'waveform') {
      return new _components_WaveformProgress_js__WEBPACK_IMPORTED_MODULE_6__["default"](options);
    }
    // Visualizer factory return null by default (unknown component name)
    return null;
  }


  /** @public
   * @member {string} - The AudioVisualizer component version */
  static get version() {
    return AudioVisualizerVersion;
  }


}


// Global scope attachment will be made when bundling this file
window.AudioVisualizer = AudioVisualizer;
/* harmony default export */ __webpack_exports__["default"] = (AudioVisualizer);


/***/ }),

/***/ "./src/js/components/FrequencyBars.js":
/*!********************************************!*\
  !*** ./src/js/components/FrequencyBars.js ***!
  \********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _utils_VisuComponentMono_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/VisuComponentMono.js */ "./src/js/utils/VisuComponentMono.js");
/* harmony import */ var _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/CanvasUtils.js */ "./src/js/utils/CanvasUtils.js");
/* harmony import */ var _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/ColorUtils.js */ "./src/js/utils/ColorUtils.js");



'use strict';


class FrequencyBars extends _utils_VisuComponentMono_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary FrequencyBars displays the audio spectrum as frequency bars in real time.
   * @author Arthur Beaulieu
   * @since 2020
   * @augments VisuComponentMono
   * @description <blockquote>This will display a single canvas with frequency from left to right be bass to high. The bar
   * height depends on audio bin intensity. The audio graph is then draw with a gradient from bottom to top that is from
   * green to red. Those color can be custom ones (see constructor options).</blockquote>
   * @param {object} options - The frequency bars options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {object[]} [options.colors] - The peak meter gradient colors, must be objects with color (in Hex/RGB/HSL) and index (in Float[0,1]) properties **/
  constructor(options) {
    super(options);
    // Peak gradient
    this._barGradient = [
      { color: options.colors ? options.colors.min || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[0] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[0], index: 0 }, // Green
      { color: options.colors ? options.colors.step0 || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[1] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[1], index: 0.7 }, // Light Green
      { color: options.colors ? options.colors.step1 || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[2] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[2], index: 0.833 }, // Orange
      { color: options.colors ? options.colors.step2 || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[3] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[3], index: 0.9 }, // Red
      { color: options.colors ? options.colors.max || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[4] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[4], index: 1 } // Light Red
    ];
    // Update canvas CSS background color
    this._canvas.style.backgroundColor = options.colors ? options.colors.background || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultBackgroundColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultBackgroundColor;
  }


  /*  ----------  VisuComponentMono overrides  ----------  */


  /** @method
   * @name _processAudioBin
   * @private
   * @override
   * @memberof FrequencyBars
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Real time method called by WebAudioAPI to process PCM data. Here we make a 8 bit frequency
   * analysis. Then we use utils method to draw bar for each audio bin in studied audio spectrum.</blockquote> **/
  _processAudioBin() {
    // Only fill again the canvas if player is playing
    if (this._isPlaying === true) {
      this._clearCanvas();
      // Get frequency data for current bin in node analyser
      const frequencyData = new Uint8Array(this._nodes.analyser.frequencyBinCount);
      this._nodes.analyser.getByteFrequencyData(frequencyData);
      // Compute single frequency width according to analyser node
      const frequencyWidth = (this._canvas.width / this._nodes.analyser.frequencyBinCount);
      // Iterate over data to build each bar
      let cursorX = 0; // X origin for items in loop
      for (let i = 0; i < this._nodes.analyser.frequencyBinCount; ++i) {
        // Compute frequency height in px, relative to the canvas height
        let frequencyHeight = (frequencyData[i] / 255) * (this._canvas.height);
        _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawVerticalBar(this._canvas, {
          height: frequencyHeight,
          width: frequencyWidth,
          colors: this._barGradient,
          originX: cursorX
        });
        // Update cursor position
        cursorX += frequencyWidth;
      }
      // Draw next frame
      requestAnimationFrame(this._processAudioBin);
    }
  }


}


/* harmony default export */ __webpack_exports__["default"] = (FrequencyBars);


/***/ }),

/***/ "./src/js/components/FrequencyCircle.js":
/*!**********************************************!*\
  !*** ./src/js/components/FrequencyCircle.js ***!
  \**********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _utils_VisuComponentMono_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/VisuComponentMono.js */ "./src/js/utils/VisuComponentMono.js");
/* harmony import */ var _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/CanvasUtils.js */ "./src/js/utils/CanvasUtils.js");
/* harmony import */ var _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/ColorUtils.js */ "./src/js/utils/ColorUtils.js");



'use strict';


class FrequencyCircle extends _utils_VisuComponentMono_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary FrequencyCircle displays a stylistic radial view in real time.
   * @author Arthur Beaulieu
   * @since 2020
   * @augments VisuComponentMono
   * @description <blockquote>This will display a single canvas with frequency displayed in. Inspired from
   * https://www.kkhaydarov.com/audio-visualizer/ and https://codepen.io/noeldelgado/pen/EaNjBy aka real mvps
   * that helped going through WebAudioAPI. It will combine a radial gradient in the background, a spinning logo
   * in the canvas center, radial frequency bars, radial oscilloscope, linear oscilloscope with it visibility handled
   * by real time audio intensity, as well as circular pulsing and glowing circle around the logo.</blockquote>
   * @param {object} options - The frequency circle options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one **/
  constructor(options) {
    super(options);
  }


  /*  ----------  VisuComponentMono overrides  ----------  */



  /** @method
   * @name _fillAttributes
   * @private
   * @override
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Internal method to fill internal properties from options object sent to constructor.</blockquote>
   * @param {object} options - The frequency circle options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {string} [options.image] - The image to put in center of canvas with a spinning animation **/
  _fillAttributes(options) {
    super._fillAttributes(options);
    // Frequency circle specific attributes
    this._imageSrc = null;
    this._centerX = null;
    this._centerY = null;
    this._radius = null;
    this._radialSection = null;
    this._barCount = null;
    this._barMaxHeight = null;
    this._circleStrokeWidth = null;
    this._stars = [];
    this._points = [];
    this._oscilloscopeRotation = null;
    // Dom specific elements for frequency circle
    this._dom.logo = null;
    // Intensity modifier
    this._averageBreakpoint = 132; // Putting breakpoint on mid amplitude [0, 255]
    this._averageHit = false;

    this._imageSrc = options.image;
    this._dom.logo = document.createElement('IMG');
    this._dom.logo.classList.add('paused');
    this._dom.logo.src = this._imageSrc ;
  }


  /** @method
   * @name _buildUI
   * @private
   * @override
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create and configure canvas then append it to given DOM element.</blockquote> **/
  _buildUI() {
    super._buildUI();
    if (this._imageSrc) { this._dom.container.appendChild(this._dom.logo); }
    this._buildBackgroundBase();
  }


  /** @method
   * @name _play
   * @private
   * @override
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On play event callback.</blockquote> **/
  _play() {
    super._play();
    this._dom.logo.classList.remove('paused'); // Resume scss animation
  }


  /** @method
   * @name _pause
   * @private
   * @override
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On pause event callback.</blockquote> **/
  _pause() {
    super._pause();
    this._dom.logo.classList.add('paused'); // Pause scss animation
  }


  /** @method
   * @name _onResize
   * @private
   * @override
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On resize event callback.</blockquote> **/
  _onResize() {
    super._onResize();
    this._circleStrokeWidth = 2;
    this._barCount = this._nodes.analyser.frequencyBinCount;
    this._centerX = this._canvas.width / 2;
    this._centerY = this._canvas.height / 2;
    this._barMaxHeight = this._canvas.height / 8;
    this._radius = (this._canvas.height / 4) - (this._canvas.height / 16);
    this._radialSection = (Math.PI * 2) / this._barCount;
    // Populating stars
    this._stars = [];
    for (let i = 0; i < 1500; ++i) {
      this._stars.push(new BackgroundStar(this._centerX, this._centerY, null, this._averageBreakpoint));
    }
    // Populating circular oscilloscope points
    this._points = [];
    for (let i = 0; i < (this._fftSize / 2); ++i) {
      this._points.push(new OscilloscopeRadialPoint({
        index: i,
        height: this._canvas.height,
        width: this._canvas.width,
        total: (this._fftSize / 2)
      }));
    }
    // Build canvas fixed base
    this._buildBackgroundBase();
  }


  /** @method
   * @name _processAudioBin
   * @private
   * @override
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Real time method called by WebAudioAPI to process PCM data. Here we make a 8 bit frequency
   * and time analysis. Then we use utils method to draw radial oscilloscope, linear point oscilloscope, background points
   * and radial frequency bars.</blockquote> **/
  _processAudioBin() {
    if (this._isPlaying === true) {
      this._clearCanvas();
      this._buildBackgroundBase();
      // Extract frequencies and times data
      const frequencies = new Uint8Array(this._nodes.analyser.frequencyBinCount);
      const times = new Uint8Array(this._nodes.analyser.frequencyBinCount);
      this._nodes.analyser.getByteFrequencyData(frequencies);
      this._nodes.analyser.getByteTimeDomainData(times);
      // Get average frequency for proccessed bin
      let average = this._getAverageFrequency(frequencies);
      this._averageHit = (average > this._averageBreakpoint);
      // Draw circle bars while retrieving aaverage amplitude
      this._animateCircleBars(frequencies);
      // Animate each star
      this._animateStars(average);
      // Draw average circle with its glow effect around center
      this._animateCircleGlow(average);
      // Draw circular oscilloscope and horizontal one if average hit
      this._animateOscilloscopes(times);
      // Request for next frame
      requestAnimationFrame(this._processAudioBin);
    }
  }


  /*  ----------  FrequencyCircle internal methods  ----------  */


  /** @method
   * @name _processAudioBin
   * @private
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw radial gradient background and circle that surround image.</blockquote> **/
  _buildBackgroundBase() {
    // Build background radial gradient
    // Color value according to ManaZeak's linear background colors
    _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].drawRadialGradient(this._canvas, {
      x0: this._centerX,
      y0: this._centerY,
      r0: this._radius,
      x1: this._centerX,
      y1: this._centerY,
      r1: this._canvas.width / 2.66,
      colors: [
        { color: '#3C405D', index: 0 },
        { color: '#060609', index: 1 }
      ]
    });
    // Build logo circle border
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawCircle(this._canvas, {
      centerX: this._centerX,
      centerY: this._centerY,
      radius: this._radius,
      radStart: 0,
      radEnd: Math.PI * 2,
      width: this._circleStrokeWidth * 2 // Times two because stroke is centered on circle
    });
  }


  /** @method
   * @name _animateCircleBars
   * @private
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Compute the frequency circle shape according to audio BIN frequency array.</blockquote>
   * @param {number[]} frequencies - The frequency array for a given audio bin **/
  _animateCircleBars(frequencies) {
    // Compute radial width for each circular bar
    const barWidth = Math.round(this._radialSection * this._radius);
    // Iterate over frequencies to draw each matching frequency bin
    for (let i = 0; i < frequencies.length; ++i) {
      // Compute current bar height depending on intensity
      const barHeight = (frequencies[i] / 255) * this._barMaxHeight;
      // Use CanvasUtils to draw bar
      _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawRadialBar(this._canvas, {
        frequencyValue: frequencies[i],
        x0: this._centerX + Math.cos(this._radialSection * i - (Math.PI / 2)) * (this._radius + this._circleStrokeWidth),
        y0: this._centerY + Math.sin(this._radialSection * i - (Math.PI / 2)) * (this._radius + this._circleStrokeWidth),
        x1: this._centerX + Math.cos(this._radialSection * i - (Math.PI / 2)) * (this._radius + this._circleStrokeWidth + barHeight),
        y1: this._centerY + Math.sin(this._radialSection * i - (Math.PI / 2)) * (this._radius + this._circleStrokeWidth + barHeight),
        width: barWidth,
        color: this._averageHit ? /* Green */ '#56D45B' : /* Dark Green */ '#37C340'
      });
    }
  }


  /** @method
   * @name _animateStars
   * @private
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Animate background points to match intensity with color and radius.</blockquote>
   * @param {number} average - The average value that acts like a breakpoint for intensity **/
  _animateStars(average) {
    let tick = this._averageHit ? average / 20 : average / 60;
    for (let i = 0; i < this._stars.length; ++i) {
      let star = this._stars[i];
      // Update star position and variation
      star.updatePosition(tick, 0.6);
      // Replace star with new one if it went out canvas
      if (star.x < -this._centerX || star.x > this._centerX || star.y < -this._centerY || star.y > this._centerY) {
        star = new BackgroundStar(this._centerX, this._centerY, average, this._averageBreakpoint); // Update local variable
        this._stars[i] = star; // Save new reference
      }
      // Use CanvasUtils to draw star disc
      _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawDisc(this._canvas, {
        centerX: star.x + this._centerX,
        centerY: star.y + this._centerY,
        radius: star.radius,
        radStart: Math.PI * 2,
        radEnd: false,
        color: star.color
      });
    }
  }


  /** @method
   * @name _animateCircleGlow
   * @private
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Animate the glowing circle around centred logo.</blockquote>
   * @param {number} average - The average value that acts like a breakpoint for intensity **/
  _animateCircleGlow(average) {
    // Build average amplitude glow with color change when average breakpoint is hit
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawCircleGlow(this._canvas, {
      centerX: this._centerX,
      centerY: this._centerY,
      radius: ((this._radius * 1.33) + average) * 2, // Glow need twice radius to properly display gradient
      radStart: 0,
      radEnd: Math.PI * 2,
      colors: [
        { color: 'rgba(0, 0, 0, 0)', index: 0.48 },
        { color: (this._averageHit ? /* Green */ '#56D45B' : /* Blue */ '#48ABAF'), index: 0.5 },
        { color: 'rgba(0, 0, 0, 0)', index: 0.52 }
      ]
    });
  }


  /** @method
   * @name _animateOscilloscopes
   * @private
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw both radial and linear point oscilloscopes.</blockquote>
   * @param {number[]} times - The time domain for a given audio bin **/
  _animateOscilloscopes(times) {
    let tick = 0.05;
    let color = '#FFF';
    if (this._averageHit) {
      this._oscilloscopeRotation += tick;
      color = 'rgba(255, 193, 140, .7)'; // Orange
    } else {
      this._oscilloscopeRotation += -tick;
      color = 'rgba(125, 228, 132, 0.25)'; // Green
    }
    // Update radial oscilloscope with time values
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawRadialOscilloscope(this._canvas, {
      points: this._points,
      times: times,
      length: this._fftSize / 2,
      centerX: this._centerX,
      centerY: this._centerY,
      rotation: this._oscilloscopeRotation,
      color: color
    });
    // If breakpoint is reached, we draw stillized horizontal oscilloscope
    if (this._averageHit) {
      _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawPointsOscilloscope(this._canvas, {
        times: times,
        length: this._fftSize / 2,
        color: 'rgba(113, 201, 205, .7)'
      });
    }
  }


  /** @method
   * @name _getAverageFrequency
   * @private
   * @memberof FrequencyCircle
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Compute the average value for a given audio bin.</blockquote>
   * @param {number[]} frequencies - The frequency array for a given audio bin
   * @return {number} - The average value for a frequency bin **/
  _getAverageFrequency(frequencies) {
    let average = 0; // Output average value
    for (let i = 0; i < frequencies.length; ++i) {
      // Update average amplitude value
      average += frequencies[i];
    }
    // Return average value of frequencies
    return average / frequencies.length;
  }


}


/*  ----------  Utils class for this visualisation  ----------  */


class BackgroundStar {


  /** @summary BackgroundStar handle stars in frequency circle.
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>This will display a single canvas with frequency displayed with.</blockquote>
   * @param {number} centerX - The start x origin
   * @param {number} centerY - The start y origin
   * @param {number} [average=0] - The audio bin average value
   * @param {number} [breakpoint=132] - The size and color breakpoint value to be compared with average **/
  constructor(centerX, centerY, average = 0, breakpoint = 132) {
    // Public attributes
    this.radius = 0.4;
    this.color = '#0F8489'; // Dark blue
    this.x = Math.random() * (centerX * 2) - centerX;
    this.y = Math.random() * (centerY * 2) - centerY;
    // Private attributes
    this._z = Math.max((centerX * 2) / (centerY * 2));
    this._maxDepth = Math.max((centerX * 2) / (centerY * 2));
    // Set star variation in space
    if (Math.abs(this.x) > Math.abs(this.y)) {
      this._dx = 1.0;
      this._dy = Math.abs(this.y / this.x);
    } else {
      this._dx = Math.abs(this.x / this.y);
      this._dy = 1.0;
    }
    // Set variation relative to center
    this._dx *= (this.x > 0) ? 1 : -1;
    this._dy *= (this.y > 0) ? 1 : -1;
    this._dz = -0.1;
    // Determine color according to center or average intensity
    if (this.y > (centerY / 2)) {
      this.color = '#71C9CD'; // Light Blue
    } else if (average > breakpoint) {
      this.color = '#FF6B67'; // Red
    }
  }


  /** @method
   * @name updatePosition
   * @public
   * @memberof BackgroundStar
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Update the background star position.</blockquote>
   * @param {number} tick - The multiplier value for position variation
   * @param {number} radiusFactor - The star radius variation factor **/
  updatePosition(tick, radiusFactor) {
    // Update position
    this.x += this._dx * tick;
    this.y += this._dy * tick;
    this._z += this._dz; // Constant z variation
    // Update variation
    this._dx += this._dx * .001;
    this._dy += this._dy * .001;
    this.radius = radiusFactor + ((this._maxDepth - this._z) * .1);
  }


}


class OscilloscopeRadialPoint {


  /** @summary OscilloscopeRadialPoint handle each point in circular oscilloscope.
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create a container for oscilloscope point. Edit radius, x and y public attributes.</blockquote>
   * @param {object} options - The oscilloscope radial point option
   * @param {number} options.height - The point height
   * @param {number} options.width - The point width
   * @param {number} options.total - The divider value for angle
   * @param {number} options.index - The numerator value for angle **/
  constructor(options) {
    this._height = options.height;
    this._width = options.width;
    this._total = options.total;
    this._index = options.index;
    this._value = Math.random() * 256;
    this._radius = Math.abs(this._width) / 8;
    // Public attributes
    this.angle = (this._index * 360) / this._total;
    this.x = (this._width / 2) + this._radius * Math.sin((Math.PI / 180) * this.angle);
    this.y = (this._height / 2) + this._radius * Math.cos((Math.PI / 180) * this.angle);
    this.dx = this.x + this._value * Math.sin((Math.PI / 180) * this.angle);
    this.dy = this.y + this._value * Math.cos((Math.PI / 180) * this.angle);
  }


}


/* harmony default export */ __webpack_exports__["default"] = (FrequencyCircle);


/***/ }),

/***/ "./src/js/components/Oscilloscope.js":
/*!*******************************************!*\
  !*** ./src/js/components/Oscilloscope.js ***!
  \*******************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _utils_VisuComponentStereo_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/VisuComponentStereo.js */ "./src/js/utils/VisuComponentStereo.js");
/* harmony import */ var _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/CanvasUtils.js */ "./src/js/utils/CanvasUtils.js");
/* harmony import */ var _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/ColorUtils.js */ "./src/js/utils/ColorUtils.js");



'use strict';


class Oscilloscope extends _utils_VisuComponentStereo_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary Oscilloscope displays a merged or L/R oscilloscope in real time.
   * @author Arthur Beaulieu
   * @since 2020
   * @augments VisuComponentStereo
   * @description <blockquote>This will display a single/dual canvas with frequency displayed with.</blockquote>
   * @param {object} options - The oscilloscope options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {boolean} [options.merged=false] - Merge left and right channel into one output
   * @param {string} [options.colors] - The oscilloscope background and signal color
   * @param {string} [options.colors.signal=ColorUtils.defaultPrimaryColor] - The signal color
   * @param {string} [options.colors.background=ColorUtils.defaultPrimaryColor] - The background color **/
  constructor(options) {
    super(options);
    // Save color
    this._colors = {
      signal: options.colors ? options.colors.signal || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultPrimaryColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultPrimaryColor
    };
    // Update canvas CSS background color
    const bgColor = (options.colors ? options.colors.background || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultBackgroundColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultBackgroundColor);
    if (this._merged === true) {
      this._canvas.style.backgroundColor = bgColor;
    } else {
      this._canvasL.style.backgroundColor = bgColor;
      this._canvasR.style.backgroundColor = bgColor;
    }
    // Init oscilloscope dimensions
    this._updateDimensions();
  }


  /*  ----------  VisuComponentStereo overrides  ----------  */



  /** @method
   * @name _fillAttributes
   * @private
   * @override
   * @memberof Oscilloscope
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Internal method to fill internal properties from options object sent to constructor.</blockquote>
   * @param {object} options - The oscilloscope options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one **/
  _fillAttributes(options) {
    super._fillAttributes(options)

    // Dimensions will be computed when canvas have been created
    this._dimension = {
      height: null,
      canvasHeight: null,
      width: null
    };
  }


  /** @method
   * @name _buildUI
   * @private
   * @override
   * @memberof Oscilloscope
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create and configure canvas then append it to given DOM element.</blockquote> **/
  _buildUI() {
    super._buildUI();

    if (this._merged === true) {
      this._dom.container.removeChild(this._canvasR);
    }
  }


  /** @method
   * @name _onResize
   * @private
   * @override
   * @memberof Oscilloscope
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On resize event callback.</blockquote> **/
  _onResize() {
    super._onResize();
    this._updateDimensions();
  }


  /** @method
   * @name _processAudioBin
   * @private
   * @override
   * @memberof Oscilloscope
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Real time method called by WebAudioAPI to process PCM data. Here we make a 8 bit time
   * analysis.</blockquote> **/
  _processAudioBin() {
    if (this._isPlaying === true) {
      this._clearCanvas();

      if (this._merged === true) {
        this._mergedStereoAnalysis();
      } else {
        this._stereoAnalysis();
      }
      // Draw next frame
      requestAnimationFrame(this._processAudioBin);
    }
  }


  /*  ----------  Oscilloscope internal methods  ----------  */


  /** @method
   * @name _mergedStereoAnalysis
   * @private
   * @memberof Oscilloscope
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Perform a merged Left and Right analysis with 8 bit time domain data.</blockquote> **/
  _mergedStereoAnalysis() {
    // Create TimeDomain array with frequency bin length
    let timeDomain = new Uint8Array(this._nodes.analyser.frequencyBinCount);
    // Left/Right channel
    this._nodes.analyser.getByteTimeDomainData(timeDomain);
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawOscilloscope(this._canvasL, {
      samples: this._nodes.analyser.frequencyBinCount,
      timeDomain: timeDomain,
      color: this._colors.signal
    });
  }


  /** @method
   * @name _stereoAnalysis
   * @private
   * @memberof Oscilloscope
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Perform a separated Left and Right analysis with 8 bit time domain data.</blockquote> **/
  _stereoAnalysis() {
    // Create TimeDomain array with freqency bin length
    let timeDomain = new Uint8Array(this._nodes.analyserL.frequencyBinCount);
    // Left channel
    this._nodes.analyserL.getByteTimeDomainData(timeDomain);
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawOscilloscope(this._canvasL, {
      samples: this._nodes.analyserL.frequencyBinCount,
      timeDomain: timeDomain,
      color: this._colors.signal
    });
    // Right channel
    this._nodes.analyserR.getByteTimeDomainData(timeDomain);
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawOscilloscope(this._canvasR, {
      samples: this._nodes.analyserR.frequencyBinCount,
      timeDomain: timeDomain,
      color: this._colors.signal
    });
  }


  /** @method
   * @name _updateDimensions
   * @private
   * @memberof Oscilloscope
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Usually called on resize event, update canvas dimension to fit render to DOM object.</blockquote> **/
  _updateDimensions() {
    this._dimension.height = this._renderTo.offsetHeight - 4; // 2px borders times two channels
    this._dimension.width = this._renderTo.offsetWidth - 2; // 2px borders
    this._dimension.canvasHeight = this._dimension.height / 2;

    if (this._merged === true) {
      this._canvasL.width = this._dimension.width;
      this._canvasL.height = this._dimension.canvasHeight * 2;
    } else {
      this._canvasL.width = this._dimension.width;
      this._canvasL.height = this._dimension.canvasHeight;
      this._canvasR.width = this._dimension.width;
      this._canvasR.height = this._dimension.canvasHeight;
    }
  }


}


/* harmony default export */ __webpack_exports__["default"] = (Oscilloscope);


/***/ }),

/***/ "./src/js/components/PeakMeter.js":
/*!****************************************!*\
  !*** ./src/js/components/PeakMeter.js ***!
  \****************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _utils_VisuComponentStereo_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/VisuComponentStereo.js */ "./src/js/utils/VisuComponentStereo.js");
/* harmony import */ var _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/CanvasUtils.js */ "./src/js/utils/CanvasUtils.js");
/* harmony import */ var _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/ColorUtils.js */ "./src/js/utils/ColorUtils.js");



'use strict';


class PeakMeter extends _utils_VisuComponentStereo_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary PeakMeter displays a splited or merged peak meter for audio signal
   * @author Arthur Beaulieu
   * @since 2020
   * @augments VisuComponentStereo
   * @description <blockquote>This component display a peak meter in several configuration. It can include a scale and its legend
   * and be oriented vertically or horizontally. Modified https://github.com/esonderegger/web-audio-peak-meter</blockquote>
   * @param {object} options - The peak meter options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {boolean} [options.merged=false] - Merge left and right channel into one output
   * @param {object} [options.legend] - The peak meter legend options
   * @param {number} [options.legend.dbScaleMin=60] - The min scale value
   * @param {number} [options.legend.dbScaleTicks=6] - The tick distance, must be a multiple of scale min
   * @param {object} [options.colors] - The oscilloscope background and signal color
   * @param {string} [options.colors.background=ColorUtils.defaultPrimaryColor] - The background color
   * @param {string} [options.colors.min=#56D45B] - The gradient min value
   * @param {string} [options.colors.step0=#AFF2B3] - The gradient second value
   * @param {string} [options.colors.step1=#FFAD67] - The gradient third value
   * @param {string} [options.colors.step2=#FF6B67] - The gradient fourth value
   * @param {string} [options.colors.max=#FFBAB8] - The gradient max value **/
  constructor(options) {
    super(options);
    // Peak gradient
    this._peakGradient = [
      { color: options.colors ? options.colors.min || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[0] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[0], center: 0 }, // Green
      { color: options.colors ? options.colors.step0 || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[1] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[1], center: 0.7 }, // Light Green
      { color: options.colors ? options.colors.step1 || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[2] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[2], center: 0.833 }, // Orange
      { color: options.colors ? options.colors.step2 || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[3] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[3], center: 0.9 }, // Red
      { color: options.colors ? options.colors.max || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[4] : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAudioGradient[4], center: 1 } // Light Red
    ];
    // Update canvas CSS background color
    const bgColor = (options.colors ? options.colors.background || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultBackgroundColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultBackgroundColor);
    if (this._merged === true) {
      this._canvasL.style.backgroundColor = bgColor;
    } else {
      this._canvasL.style.backgroundColor = bgColor;
      this._canvasR.style.backgroundColor = bgColor;
    }
  }


  /*  ----------  VisuComponentStereo overrides  ----------  */


  /** @method
   * @name _fillAttributes
   * @private
   * @override
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Internal method to fill internal properties from options object sent to constructor.</blockquote>
   * @param {object} options - The frequency circle options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one **/
  _fillAttributes(options) {
    super._fillAttributes(options);
    this._orientation = options.orientation || 'horizontal';
    this._legend = options.legend || null;

    if (this._legend) {
      this._dbScaleMin = options.legend.dbScaleMin || 60;
      this._dbScaleTicks = options.legend.dbScaleTicks || 15;
    } else {
      this._dbScaleMin = 60;
      this._dbScaleTicks = 15;
    }

    this._amplitudeL = 0;
    this._amplitudeR = 0;
    this._peakL = 0;
    this._peakR = 0;
    this._peakSetTimeL = null;
    this._peakSetTimeR = null;
    this._dom.scaleContainer = null;
    this._dom.labels = [];
  }


  /** @method
   * @name _buildUI
   * @private
   * @override
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create and configure canvas then append it to given DOM element.</blockquote> **/
  _buildUI() {
    super._buildUI();

    if (this._orientation === 'horizontal') {
      this._dom.container.classList.add('horizontal-peakmeter');
    }

    if (this._legend) {
      this._dom.scaleContainer = document.createElement('DIV');
      this._dom.scaleContainer.classList.add('scale-container');
      this._dom.container.insertBefore(this._dom.scaleContainer, this._dom.container.firstChild);
    }

    if (this._merged === true) {
      this._dom.container.removeChild(this._canvasR);
    }

    this._updateDimensions();

    if (this._legend) {
      this._createPeakLabel();
      this._createScaleTicks();
    }
  }


  /** @method
   * @name _setAudioNodes
   * @private
   * @override
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Build audio chain with source.</blockquote> **/
  _setAudioNodes() {
    super._setAudioNodes();
    this._peakSetTimeL = this._audioCtx.currentTime;
    this._peakSetTimeR = this._audioCtx.currentTime;
  }


  /** @method
   * @name _pause
   * @private
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On pause event callback.</blockquote> **/
  _pause() {
    super._pause();
    if (this._legend) {
      this._dom.labels[0].textContent = '-∞';
      this._dom.labels[1].textContent = '-∞';
    }
  }


  /** @method
   * @name _onResize
   * @private
   * @override
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On resize event callback.</blockquote> **/
  _onResize() {
    super._onResize();
    this._updateDimensions();

    if (this._legend) {
      this._createPeakLabel();
      this._createScaleTicks();
    }
  }


  /** @method
   * @name _processAudioBin
   * @private
   * @override
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Real time method called by WebAudioAPI to process PCM data. Here we make a 8 bit frequency
   * and time analysis. Then we use utils method to draw radial oscilloscope, linear point oscilloscope, background points
   * and radial frequency bars.</blockquote> **/
  _processAudioBin() {
    if (this._isPlaying === true) {
      this._clearCanvas();

      if (this._merged === true) {
        this._mergedStereoAnalysis();
      } else {
        this._stereoAnalysis();
      }
      // Draw next frame
      requestAnimationFrame(this._processAudioBin);
    }
  }


  /*  ----------  PeakMeter internal methods  ----------  */


  /** @method
   * @name _mergedStereoAnalysis
   * @private
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Perform a merged Left and Right analysis with 32 bit time domain data.</blockquote> **/
  _mergedStereoAnalysis() {
    const data = new Float32Array(this._fftSize);
    this._nodes.analyser.getFloatTimeDomainData(data);
    // Compute average power over the interval and average power attenuation in DB
    let sumOfSquares = 0;
    for (let i = 0; i < data.length; i++) {
      sumOfSquares += data[i] ** 2;
    }

    const avgPowerDecibels = 10 * Math.log10(sumOfSquares / data.length);
    // Compure amplitude from width or height depending on orientation
    const dbScaleBound = this._dbScaleMin * -1;
    if (this._orientation === 'horizontal') {
      this._amplitudeL = Math.floor((avgPowerDecibels * this._canvasL.width) / dbScaleBound);
    } else if (this._orientation === 'vertical') {
      this._amplitudeL = Math.floor((avgPowerDecibels * this._canvasL.height) / dbScaleBound);
    }
    // Left channel
    // Found a new max value (peak) [-this._dbScaleMin, 0] interval
    if (this._peakL > this._amplitudeL) {
      this._peakL = this._amplitudeL;
      this._peakSetTimeL = this._audioCtx.currentTime;
      // Update peak label
      if (this._legend) {
        avgPowerDecibels !== -Infinity ? this._dom.labels[0].textContent = _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].precisionRound(avgPowerDecibels, 1) : null;
      }
    } else if (this._audioCtx.currentTime - this._peakSetTimeL > 1) {
      this._peakL = this._amplitudeL;
      this._peakSetTimeL = this._audioCtx.currentTime;
      // Update peak label
      if (this._legend) {
        avgPowerDecibels !== -Infinity ? this._dom.labels[0].textContent = _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].precisionRound(avgPowerDecibels, 1) : null;
      }
    }
    // Draw left and right peak meters
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawPeakMeter(this._canvasL, {
      amplitude: this._amplitudeL,
      peak: this._peakL,
      orientation: this._orientation,
      colors: this._peakGradient
    });
  }


  /** @method
   * @name _stereoAnalysis
   * @private
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Perform a separated Left and Right analysis with 32 bit time domain data.</blockquote> **/
  _stereoAnalysis() {
    const dataL = new Float32Array(this._fftSize);
    const dataR = new Float32Array(this._fftSize);
    this._nodes.analyserL.getFloatTimeDomainData(dataL);
    this._nodes.analyserR.getFloatTimeDomainData(dataR);
    // Compute average power over the interval and average power attenuation in DB
    let sumOfSquaresL = 0;
    let sumOfSquaresR = 0;
    for (let i = 0; i < dataL.length; i++) {
      sumOfSquaresL += dataL[i] ** 2;
      sumOfSquaresR += dataR[i] ** 2;
    }
    const avgPowerDecibelsL = 10 * Math.log10(sumOfSquaresL / dataL.length);
    const avgPowerDecibelsR = 10 * Math.log10(sumOfSquaresR / dataR.length);
    // Compure amplitude from width or height depending on orientation
    const dbScaleBound = this._dbScaleMin * -1;
    if (this._orientation === 'horizontal') {
      this._amplitudeL = Math.floor((avgPowerDecibelsL * this._canvasL.width) / dbScaleBound);
      this._amplitudeR = Math.floor((avgPowerDecibelsR * this._canvasR.width) / dbScaleBound);
    } else if (this._orientation === 'vertical') {
      this._amplitudeL = Math.floor((avgPowerDecibelsL * this._canvasL.height) / dbScaleBound);
      this._amplitudeR = Math.floor((avgPowerDecibelsR * this._canvasR.height) / dbScaleBound);
    }
    // Left channel
    // Found a new max value (peak) [-this._dbScaleMin, 0] interval
    if (this._peakL > this._amplitudeL) {
      this._peakL = this._amplitudeL;
      this._peakSetTimeL = this._audioCtx.currentTime;
      // Update peak label
      if (this._legend) {
        avgPowerDecibelsL !== -Infinity ? this._dom.labels[0].textContent = _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].precisionRound(avgPowerDecibelsL, 1) : null;
      }
    } else if (this._audioCtx.currentTime - this._peakSetTimeL > 1) {
      this._peakL = this._amplitudeL;
      this._peakSetTimeL = this._audioCtx.currentTime;
      // Update peak label
      if (this._legend) {
        avgPowerDecibelsL !== -Infinity ? this._dom.labels[0].textContent = _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].precisionRound(avgPowerDecibelsL, 1) : null;
      }
    }
    // Right channel
    // Found a new max value (peak) [-this._dbScaleMin, 0] interval
    if (this._peakR > this._amplitudeR) {
      this._peakR = this._amplitudeR;
      this._peakSetTimeR = this._audioCtx.currentTime;
      // Update peak label
      if (this._legend) {
        avgPowerDecibelsR !== -Infinity ? this._dom.labels[1].textContent = _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].precisionRound(avgPowerDecibelsR, 1) : null;
      }
    } else if (this._audioCtx.currentTime - this._peakSetTimeR > 1) {
      this._peakR = this._amplitudeL;
      this._peakSetTimeR = this._audioCtx.currentTime;
      // Update peak label
      if (this._legend) {
        avgPowerDecibelsR !== -Infinity ? this._dom.labels[1].textContent = _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].precisionRound(avgPowerDecibelsR, 1) : null;
      }
    }
    // Draw left and right peak meters
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawPeakMeter(this._canvasL, {
      amplitude: this._amplitudeL,
      peak: this._peakL,
      orientation: this._orientation,
      colors: this._peakGradient
    });
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawPeakMeter(this._canvasR, {
      amplitude: this._amplitudeR,
      peak: this._peakR,
      orientation: this._orientation,
      colors: this._peakGradient
    });
  }


  /** @method
   * @name _createScaleTicks
   * @private
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Build the scale tick depending on component orientation.</blockquote> **/
  _createScaleTicks() {
    const numTicks = Math.floor(this._dbScaleMin / this._dbScaleTicks);
    let dbTickLabel = 0;
    this._dom.scaleContainer.innerHTML = '';
    if (this._orientation === 'horizontal') {
      const tickWidth = this._canvasL.width / numTicks;
      for (let i = 0; i < numTicks; ++i) {
        const dbTick = document.createElement('DIV');
        this._dom.scaleContainer.appendChild(dbTick);
        dbTick.style.width = `${tickWidth}px`;
        dbTick.textContent = `${dbTickLabel}`;
        dbTickLabel -= this._dbScaleTicks;
      }
    } else {
      const tickHeight = this._canvasL.height / numTicks;
      for (let i = 0; i < numTicks; ++i) {
        const dbTick = document.createElement('DIV');
        this._dom.scaleContainer.appendChild(dbTick);
        dbTick.style.height = `${tickHeight}px`;
        dbTick.textContent = `${dbTickLabel}`;
        dbTickLabel -= this._dbScaleTicks;
      }
    }
  }


  /** @method
   * @name _createPeakLabel
   * @private
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Build the scale legend depending on component orientation.</blockquote> **/
  _createPeakLabel() {
    if (this._dom.labels.length === 2) {
      this._dom.container.removeChild(this._dom.labels[0]);
      this._dom.container.removeChild(this._dom.labels[1]);
      this._dom.labels = [];
    }

    const peakLabelL = document.createElement('DIV');
    const peakLabelR = document.createElement('DIV');
    peakLabelL.classList.add('peak-value-container');
    peakLabelR.classList.add('peak-value-container');
    peakLabelL.textContent = '-∞';
    peakLabelR.textContent = '-∞';

    if (this._orientation === 'horizontal') {
      peakLabelL.style.width = '28px';
      peakLabelL.style.height = `${this._canvasL.height + 2}px`; // 2 px borders
      peakLabelL.style.top = '14px';
      peakLabelR.style.width = '28px';
      peakLabelR.style.height = `${this._canvasL.height + 2}px`; // 2 px borders
      peakLabelR.style.top = `${this._canvasL.height + 16}px`; // 2px borders + 14px height
    } else {
      peakLabelL.style.width = `${this._canvasL.width + 2}px`; // 2 px borders
      peakLabelL.style.left = '18px';
      peakLabelR.style.width = `${this._canvasL.width + 2}px`; // 2 px borders
      peakLabelR.style.left = `${this._canvasL.width + 20}px`; // 2px borders + 18px width
    }

    this._dom.labels.push(peakLabelL);
    this._dom.labels.push(peakLabelR);
    this._dom.container.appendChild(this._dom.labels[0]);
    this._dom.container.appendChild(this._dom.labels[1]);
  }


  /** @method
   * @name _updateDimensions
   * @private
   * @memberof PeakMeter
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Usually called on resize event, update canvas dimension to fit render to DOM object.</blockquote> **/
  _updateDimensions() {
    let widthOffset = 0;
    let heightOffset = 0;

    if (this._orientation === 'horizontal') {
      if (this._legend) {
        widthOffset = 30;
        heightOffset = 14;
      }

      this._canvasL.width = this._renderTo.offsetWidth - widthOffset; // 2px borders + 28 px with for label

      if (this._merged === true) {
        this._canvasL.height = (this._renderTo.offsetHeight - heightOffset) - 2; // 2px border + scale height 14px
        this._canvasR.height = (this._renderTo.offsetHeight - heightOffset) - 2; // 2px border + scale height 14px
      } else {
        this._canvasR.width = this._renderTo.offsetWidth - widthOffset; // 2px borders + 28 px with for label
        this._canvasL.height = (this._renderTo.offsetHeight - heightOffset) / 2 - 2; // 2px border + scale height 14px
        this._canvasR.height = (this._renderTo.offsetHeight - heightOffset) / 2 - 2; // 2px border + scale height 14px
      }

      if (this._legend) {
        this._dom.scaleContainer.style.width = `${this._canvasL.width}px`;
      }
    } else if (this._orientation === 'vertical') {
      if (this._legend) {
        widthOffset = 18;
        heightOffset = 16;
      } else {
        this._canvasL.style.left = '0'; // Remove left offset for legend
      }

      this._canvasL.height = this._renderTo.offsetHeight - heightOffset - 2; // 2px borders + 16px height for label

      if (this._merged === true) {
        this._canvasL.width = (this._renderTo.offsetWidth - widthOffset) - 2; // 2px border + scale width 18px
        this._canvasR.width = (this._renderTo.offsetWidth - widthOffset) - 2; // 2px border + scale width 18px
      } else {
        this._canvasR.height = this._renderTo.offsetHeight - heightOffset - 2; // 2px borders + 16px height for label
        this._canvasL.width = (this._renderTo.offsetWidth - widthOffset) / 2 - 2; // 2px border + scale width 18px
        this._canvasR.width = (this._renderTo.offsetWidth - widthOffset) / 2 - 2; // 2px border + scale width 18px
      }

      if (this._legend) {
        this._dom.scaleContainer.style.height = `${this._canvasL.height}px`;
        this._dom.scaleContainer.style.width = '18px';
      }
    }
  }


}


/* harmony default export */ __webpack_exports__["default"] = (PeakMeter);


/***/ }),

/***/ "./src/js/components/Spectrum.js":
/*!***************************************!*\
  !*** ./src/js/components/Spectrum.js ***!
  \***************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _utils_VisuComponentStereo_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/VisuComponentStereo.js */ "./src/js/utils/VisuComponentStereo.js");

'use strict';


class Spectrum extends _utils_VisuComponentStereo_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary Spectrum displays real time audio frequencies as vertical bars that scroll over time
   * @author Arthur Beaulieu
   * @since 2020
   * @augments VisuComponentStereo
   * @description <blockquote>.</blockquote>
   * @param {object} options - The spectrum options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {boolean} [options.merged=false] - Merge left and right channel into one output
   * @param {boolean} [options.scale=false] - The peak meter legend
   * @param {boolean} [options.colorSmoothing=false] - Display color intensity with a gradient to next sample value **/
  constructor(options) {
    super(options);
    this._updateDimensions();
    this._createLogarithmicScaleHeights();
    // Update canvas CSS background color
    const bgColor = 'black';
    if (this._merged === true) {
      this._canvasL.style.backgroundColor = bgColor;
    } else {
      this._canvasL.style.backgroundColor = bgColor;
      this._canvasR.style.backgroundColor = bgColor;
    }
  }


  /*  ----------  VisuComponentStereo overrides  ----------  */


  /** @method
   * @name _fillAttributes
   * @private
   * @override
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Internal method to fill internal properties from options object sent to constructor.</blockquote>
   * @param {object} options - The frequency circle options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {boolean} [options.scale=false] - The peak meter legend
   * @param {boolean} [options.colorSmoothing=false] - Display color intensity with a gradient to next sample value **/
  _fillAttributes(options) {
    super._fillAttributes(options);
    // Spectrum specific attributes
    this._scaleType = options.scale || 'linear';
    this._colorSmoothing = options.colorSmoothing || false;
    this._canvasSpeed = 1; // Canvas offset per bin
    // Used to animate canvas on audio bins analysis
    this._bufferCanvas = null;
    this._bufferCtx = null;
    // Display utils
    this._dom.settings = null;
    this._dom.settingsPanel = null;
    this._dimension = {
      height: null,
      canvasHeight: null,
      width: null
    };
    this._logScale = [];
    // Event binding
    this._settingsClicked = this._settingsClicked.bind(this);
    this._clickedElsewhere = this._clickedElsewhere.bind(this);
  }


  /** @method
   * @name _buildUI
   * @private
   * @override
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create and configure canvas then append it to given DOM element.</blockquote> **/
  _buildUI() {
    super._buildUI();
    this._bufferCanvas = document.createElement('CANVAS');
    this._bufferCtx = this._bufferCanvas.getContext('2d');

    if (this._merged === true) {
      this._dom.container.removeChild(this._canvasR);
    }
    // Update canvas dimensions
    this._canvasL.width = this._dimension.width;
    this._canvasL.height = this._dimension.canvasHeight;
    this._canvasR.width = this._dimension.width;
    this._canvasR.height = this._dimension.canvasHeight;
    this._bufferCanvas.width = this._dimension.width;
    this._bufferCanvas.height = this._dimension.canvasHeight;
    // Create option button
    const parser = new DOMParser();
    this._dom.settings = parser.parseFromString(`<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"><path d="M24 13.616v-3.232c-1.651-.587-2.694-.752-3.219-2.019v-.001c-.527-1.271.1-2.134.847-3.707l-2.285-2.285c-1.561.742-2.433 1.375-3.707.847h-.001c-1.269-.526-1.435-1.576-2.019-3.219h-3.232c-.582 1.635-.749 2.692-2.019 3.219h-.001c-1.271.528-2.132-.098-3.707-.847l-2.285 2.285c.745 1.568 1.375 2.434.847 3.707-.527 1.271-1.584 1.438-3.219 2.02v3.232c1.632.58 2.692.749 3.219 2.019.53 1.282-.114 2.166-.847 3.707l2.285 2.286c1.562-.743 2.434-1.375 3.707-.847h.001c1.27.526 1.436 1.579 2.019 3.219h3.232c.582-1.636.75-2.69 2.027-3.222h.001c1.262-.524 2.12.101 3.698.851l2.285-2.286c-.744-1.563-1.375-2.433-.848-3.706.527-1.271 1.588-1.44 3.221-2.021zm-12 2.384c-2.209 0-4-1.791-4-4s1.791-4 4-4 4 1.791 4 4-1.791 4-4 4z"/></svg>`, 'image/svg+xml').documentElement;
    this._dom.settings.classList.add('audio-spectrum-settings');
    this._dom.settingsPanel = document.createElement('DIV');
    this._dom.settingsPanel.classList.add('audio-spectrum-settings-panel');
    this._dom.settingsPanel.innerHTML = `
      <h3>Settings</h3>
      <form>
        <p class="legend">Scale:</p>
        <label for="linear">Linear</label>
        <input type="radio" id="id-linear" name="scale" value="linear" ${this._scaleType === 'linear' ? 'checked' : ''}>
        <label for="logarithmic">Logarithmic</label>
        <input type="radio" id="id-logarithmic" name="scale" value="logarithmic" ${this._scaleType === 'logarithmic' ? 'checked' : ''}>
        <p class="smooth-color">
          <label for="smoothColor">Smooth colors</label>
          <input type="checkbox" id="smoothColor" name="smoothColor" ${this._colorSmoothing ? 'checked' : ''}>
        </p>
      </form>
    `;
    const form = this._dom.settingsPanel.querySelector('form');
    form.addEventListener('change', event => {
      event.preventDefault(); // Prevent location redirection with params
      const data = new FormData(form);
      const output = [];
      // Iterate over radios to extract values
      for (const entry of data) {
        output.push(entry[1]);
      }
      // Update canvas scale
      this._scaleType = output[0];
      // Set color smoothing from checkbox
      this._colorSmoothing = (output[1] === 'on');
    }, false);
    // Add display canvas to renderTo parent
    this._dom.container.appendChild(this._dom.settingsPanel); // Append panel before to emulate z-index under settings button w/ no scss rules of z-index
    this._dom.container.appendChild(this._dom.settings);
    this._dom.settings.addEventListener('click', this._settingsClicked, false);
  }


  /** @method
   * @name _removeEvents
   * @private
   * @override
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Add component events (resize, play, pause, dbclick).</blockquote> **/
  _removeEvents() {
    super._removeEvents();
    document.body.removeEventListener('click', this._clickedElsewhere, false);
  }


  /** @method
   * @name _onResize
   * @private
   * @override
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On resize event callback.</blockquote> **/
  _onResize() {
    super._onResize();
    this._updateDimensions();
    this._createLogarithmicScaleHeights();
    // Update canvas dimensions
    this._canvasL.width = this._dimension.width;
    this._canvasL.height = this._dimension.canvasHeight;

    if (this._merged === false) {
      this._canvasR.width = this._dimension.width;
      this._canvasR.height = this._dimension.canvasHeight;
    }

    this._bufferCanvas.width = this._dimension.width;
    this._bufferCanvas.height = this._dimension.canvasHeight;
  }


  /** @method
   * @name _processAudioBin
   * @private
   * @override
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Real time method called by WebAudioAPI to process PCM data. Here we make a 8 bit frequency
   * and time analysis.</blockquote> **/
  _processAudioBin() {
    if (this._isPlaying === true) {
      if (this._merged === true) {
        this._mergedStereoAnalysis();
      } else {
        this._stereoAnalysis();
      }

      requestAnimationFrame(this._processAudioBin);
    }
  }


  /*  ----------  Spectrum internal methods  ----------  */


  /** @method
   * @name _mergedStereoAnalysis
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Perform a merged Left and Right analysis with 32 bit time domain data.</blockquote> **/
  _mergedStereoAnalysis() {
    const frequencies = new Uint8Array(this._nodes.analyser.frequencyBinCount);
    this._nodes.analyser.getByteFrequencyData(frequencies);
    this._drawSpectrogramForFrequencyBin(this._canvasL, frequencies);
  }


  /** @method
   * @name _stereoAnalysis
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Perform a separated Left and Right analysis with 32 bit time domain data.</blockquote> **/
  _stereoAnalysis() {
    const frequenciesL = new Uint8Array(this._nodes.analyserL.frequencyBinCount);
    const frequenciesR = new Uint8Array(this._nodes.analyserR.frequencyBinCount);
    this._nodes.analyserL.getByteFrequencyData(frequenciesL);
    this._nodes.analyserR.getByteFrequencyData(frequenciesR);
    this._drawSpectrogramForFrequencyBin(this._canvasL, frequenciesL);
    this._drawSpectrogramForFrequencyBin(this._canvasR, frequenciesR);
  }


  /** @method
   * @name _updateDimensions
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Usually called on resize event, update canvas dimension to fit render to DOM object.</blockquote> **/
  _updateDimensions() {
    this._dimension.width = this._renderTo.offsetWidth - 2;  // 2px borders

    if (this._merged === true) {
      this._dimension.height = this._renderTo.offsetHeight - 2; // 2px borders
      this._dimension.canvasHeight = this._dimension.height;
    } else {
      this._dimension.height = this._renderTo.offsetHeight - 4; // 2px borders times two channels
      this._dimension.canvasHeight = this._dimension.height / 2;
    }
  }


  /** @method
   * @name _settingsClicked
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Spectrum settings button callback.</blockquote> **/
  _settingsClicked() {
    const opened = this._dom.settingsPanel.classList.contains('opened');
    if (opened === false) { // If opened, settings closure will be handled in clickedElsewhere
      this._dom.settings.classList.add('opened');
      this._dom.settingsPanel.classList.add('opened');
      document.body.addEventListener('click', this._clickedElsewhere, false);
    }
  }


  /** @method
   * @name _clickedElsewhere
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Callback when a clicked is detected and settings context is open.</blockquote>
   * @param {object} event - The click event **/
  _clickedElsewhere(event) {
    if (!event.target.closest('.audio-spectrum-settings') && !event.target.closest('.audio-spectrum-settings-panel')) {
      this._dom.settings.classList.remove('opened');
      this._dom.settingsPanel.classList.remove('opened');
      document.body.removeEventListener('click', this._clickedElsewhere, false);
    }
  }


  /** @method
   * @name _drawSpectrogramForFrequencyBin
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a vertical ray representing the audio frequencies at process time.</blockquote>
   * @param {object} canvas - The canvas to draw spectrum ray into
   * @param {Uint8Array} frequencies - The frequencies for a given audio bin **/
  _drawSpectrogramForFrequencyBin(canvas, frequencies) {
    const ctx = canvas.getContext('2d');
    // Copy previous image
    this._bufferCtx.drawImage(canvas, 0, 0, this._dimension.width, this._dimension.canvasHeight);
    // Array length is always (fftSize / 2)
    for (let i = 0; i < frequencies.length; ++i) {
      if (this._scaleType === 'linear') {
        this._fillRectLinear(ctx, frequencies, i);
      } else {
        this._fillRectLogarithm(ctx, frequencies, i);
      }
    }
    // Offset canvas to the left and paste stored image
    ctx.translate(-this._canvasSpeed, 0);
    ctx.drawImage(this._bufferCanvas, 0, 0, this._dimension.width, this._dimension.canvasHeight, 0, 0, this._dimension.width, this._dimension.canvasHeight);
    ctx.setTransform(1, 0, 0, 1, 0, 0); // Reset the transformation matrix
  }


  /** @method
   * @name _drawSpectrogramForFrequencyBin
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw the vertical ray with a linear scale.</blockquote>
   * @param {object} ctx - The canvas context
   * @param {Uint8Array} frequencies - The frequencies for a given audio bin
   * @param {number} i - The index to scale linearly **/
  _fillRectLinear(ctx, frequencies, i) {
    const scaledHeight = this._scaleLinearIndexToHeight(i);
    const frequencyHeight = this._dimension.canvasHeight / frequencies.length;
    if (i === 0 || !this._colorSmoothing) {
      ctx.fillStyle = `rgb(${frequencies[i]}, ${frequencies[i]}, ${frequencies[i]})`;
    } else {
      const gradient = ctx.createLinearGradient(
        0, this._dimension.canvasHeight - scaledHeight - frequencyHeight, // X0/Y0
        0, this._dimension.canvasHeight - scaledHeight // X1/Y1
      );
      // Add color stops from current color to previous sample color
      gradient.addColorStop(0, `rgb(${frequencies[i]}, ${frequencies[i]}, ${frequencies[i]})`);
      gradient.addColorStop(1, `rgb(${frequencies[i - 1]}, ${frequencies[i - 1]}, ${frequencies[i - 1]})`);
      ctx.fillStyle = gradient;
    }
    // Linear scale
    ctx.fillRect(
      this._dimension.width - this._canvasSpeed, // X pos
      this._dimension.canvasHeight - scaledHeight - frequencyHeight, // Y pos
      this._canvasSpeed, // Width is speed value
      frequencyHeight // Height depends on canvas height
    );
  }


  /** @method
   * @name _drawSpectrogramForFrequencyBin
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw the vertical ray with a logarithm scale.</blockquote>
   * @param {object} ctx - The canvas context
   * @param {Uint8Array} frequencies - The frequencies for a given audio bin
   * @param {number} i - The index to scale logarithmically **/
  _fillRectLogarithm(ctx, frequencies, i) {
    if (i === 0 || i === frequencies.length - 1 || !this._colorSmoothing) {
      ctx.fillStyle = `rgb(${frequencies[i]}, ${frequencies[i]}, ${frequencies[i]})`;
    } else {
      const gradient = ctx.createLinearGradient(
        0, this._logScale[i], // X0/Y0
        0, this._logScale[i - 1] // X1/Y1
      );
      // Add color stops from current color to previous sample color
      gradient.addColorStop(0, `rgb(${frequencies[i]}, ${frequencies[i]}, ${frequencies[i]})`);
      gradient.addColorStop(1, `rgb(${frequencies[i - 1]}, ${frequencies[i - 1]}, ${frequencies[i - 1]})`);
      ctx.fillStyle = gradient;
    }
    // Log scale
    ctx.fillRect(
      this._dimension.width - this._canvasSpeed, // X pos
      this._logScale[i - 1], // Y pos
      this._canvasSpeed, // Width is speed value
      this._logScale[i] - this._logScale[i - 1] // Height is computed with previous sample offset
    );
  }


  /** @method
   * @name _scaleLinearIndexToHeight
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Convert linear value to logarithmic value.</blockquote>
   * @param {number} index - The canvas context **/
  _scaleLinearIndexToHeight(index) {
    // Convert a range to another, maintaining ratio
    // oldRange = (oldMax - oldMin)
    // newRange = (newMax - newMin)
    // newValue = (((oldValue - oldMin) * newRange) / oldRange) + NewMin */
    // Convert from [0, (this._fftSize / 2)] to [0, this._dimension.canvasHeight] (frequency array length scale to canvas height scale)
    const oldRange = this._fftSize / 2;
    const newRange = this._dimension.canvasHeight;
    return (index * newRange) / oldRange;
  }


  /** @method
   * @name _createLogarithmicScaleHeights
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Pre-compute samples height on a logarithmic scale to avoid computation on render process.</blockquote> **/
  _createLogarithmicScaleHeights() {
    return new Promise(resolve => {
      this._logScale = [this._dimension.canvasHeight]; // Reset previously made scale
      for (let i = 1; i < (this._fftSize / 2); ++i) { // Log(0) forbidden, we offset
        this._logScale.push(this._computeLogSampleHeight(i)); // For each frequency sample, compute its log height offset from origin
      }
      resolve();
    });
  }


  /** @method
   * @name _computeLogSampleHeight
   * @private
   * @memberof Spectrum
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Compute log sample height in canvas.</blockquote>
   * @param {number} sample - The sample to compute its log height **/
  _computeLogSampleHeight(sample) {
    return this._dimension.canvasHeight - (((Math.log(sample) / Math.log(10)) / (Math.log(this._fftSize / 2) / Math.log(10))) * this._dimension.canvasHeight);
  }


}


/* harmony default export */ __webpack_exports__["default"] = (Spectrum);


/***/ }),

/***/ "./src/js/components/Timeline.js":
/*!***************************************!*\
  !*** ./src/js/components/Timeline.js ***!
  \***************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _utils_VisuComponentMono_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/VisuComponentMono.js */ "./src/js/utils/VisuComponentMono.js");
/* harmony import */ var _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/CanvasUtils.js */ "./src/js/utils/CanvasUtils.js");
/* harmony import */ var _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ../utils/ColorUtils.js */ "./src/js/utils/ColorUtils.js");



'use strict';


const MAX_CANVAS_WIDTH = 32000;


class Timeline extends _utils_VisuComponentMono_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary Timeline displays a scrolling audio waveform.
   * @author Arthur Beaulieu
   * @since 2020
   * @augments VisuComponentMono
   * @description <blockquote>Will display a waveform that scrolls over playback. If provided, BPM is visualised as
   * vertical bars with emphasis on main beats according to time signature. It is interactive and will update the player's
   * current time value to match the dragged one. This class extends VisuComponentMono only because it performs an offline
   * analysis on audio and the stereo information are already held in audio buffer.</blockquote>
   * @param {object} options - The timeline options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {object} [options.beat=null] - The beat configuration
   * @param {object} [options.beat.offset=null] - offset before first beat
   * @param {object} [options.beat.bpm=null] - The track bpm
   * @param {object} [options.beat.timeSignature=null] - The track time signature to put emphasis on main beats
   * @param {object} [options.colors] - Timeline color potions
   * @param {object} [options.colors.background='#1D1E25'] - Canvas background color in Hex/RGB/HSL
   * @param {object} [options.colors.track='#12B31D'] - The timeline color in Hex/RGB/HSL
   * @param {object} [options.colors.mainBeat='#56D45B'] - The main beat triangles color in Hex/RGB/HSL
   * @param {object} [options.colors.subBeat='#FF6B67'] - The sub beat triangles color in Hex/RGB/HSL **/
  constructor(options) {
    super(options);

    this._colors = {
      background: options.colors ? options.colors.background || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultBackgroundColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultBackgroundColor,
      track: options.colors ? options.colors.track || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultDarkPrimaryColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultDarkPrimaryColor,
      mainBeat: options.colors ? options.colors.mainBeat || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultPrimaryColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultPrimaryColor,
      subBeat: options.colors ? options.colors.subBeat || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAntiPrimaryColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAntiPrimaryColor
    };

    this._canvas.style.backgroundColor = this._colors.background;

    this._canvasSpeed = options.speed ? options.speed : 5.0; // Time in seconds

    this._beat = {
      offset: options.beat ? options.beat.offset : null,
      bpm: options.beat ? options.beat.bpm : null,
      timeSignature: options.beat ? options.beat.timeSignature : null,
    };

    this._beats = [];
    this._hotCues = [];
    // Offline canvas -> main canvas is divided with 32k px wide canvases
    this._canvases = [];
    this._cueCanvases = [];
    this._beatCanvases = [];
    // Drag canvas utils
    this._isDragging = false;
    this._wasPlaying = false;
    this._draggedTime = 0;
    this._startDrag = {
      x: 0,
      y: 0
    };

    if (this._player.src !== '') {
      this._getPlayerSourceFile();
    }
  }


  /*  ----------  VisuComponentMono overrides  ----------  */



  /** @method
   * @name _fillAttributes
   * @private
   * @override
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Internal method to fill internal properties from options object sent to constructor.</blockquote>
   * @param {object} options - The frequency circle options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one **/
  _fillAttributes(options) {
    super._fillAttributes(options);
    this._offlineCtx = null;
    this._offlineBuffer = null;
    // Local event binding
    this._trackLoaded = this._trackLoaded.bind(this);
    this._onProgress = this._onProgress.bind(this);
    this._mouseDown = this._mouseDown.bind(this);
    this._mouseMove = this._mouseMove.bind(this);
    this._mouseUp = this._mouseUp.bind(this);
  }


  /** @method
   * @name _addEvents
   * @private
   * @override
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Add component events (resize, play, pause, dbclick).</blockquote> **/
  _addEvents() {
    super._addEvents();
    this._player.addEventListener('loadedmetadata', this._trackLoaded, false);
    this._player.addEventListener('seeking', this._onProgress, false);
    this._canvas.addEventListener('mousedown', this._mouseDown, false);
  }


  /** @method
   * @name _removeEvents
   * @private
   * @override
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Remove component events (resize, play, pause, dbclick).</blockquote> **/
  _removeEvents() {
    super._removeEvents();
    this._player.removeEventListener('loadedmetadata', this._trackLoaded, false);
    this._player.removeEventListener('seeking', this._onProgress, false);
  }


  /** @method
   * @name _onResize
   * @private
   * @override
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On resize event callback.</blockquote> **/
  _onResize() {
    super._onResize();
    this._fillData();
    this._clearCanvas();
    this._clearCueCanvas();
    this._drawTimeline(this._player.currentTime);
  }


  /** @method
   * @name _dblClick
   * @private
   * @override
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On double click event callback.</blockquote> **/
  _dblClick() {
    // Required to revoke fullscreen toggle from parent class, as it interferes with drag feature
  }


  /** @method
   * @name _processAudioBin
   * @private
   * @override
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Real time method called by WebAudioAPI to process PCM data. Here we make a 8 bit frequency
   * and time analysis.</blockquote> **/
  _processAudioBin() {
    if (this._isPlaying === true) {
      this._clearCanvas();
      this._clearCueCanvas();
      this._drawTimeline(this._player.currentTime);
      requestAnimationFrame(this._processAudioBin);
    }
  }


  /*  ----------  Timeline internal methods  ----------  */


  /** @method
   * @name _trackLoaded
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Player callback on track loaded.</blockquote> **/
  _trackLoaded() {
    cancelAnimationFrame(this._processAudioBin);
    this._clearCanvas(); // Clear previous canvas
    this._clearCueCanvas();
    // Do XHR to request file and parse it
    this._getPlayerSourceFile();
  }


  /** @method
   * @name _onProgress
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On progress callback.</blockquote> **/
  _onProgress() {
    this._clearCanvas();
    this._clearCueCanvas();
    this._drawTimeline(this._player.currentTime || 0);
  }


  /** @method
   * @name _mouseDown
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Mouse down callback.</blockquote>
   * @param {object} event - The mouse down event **/
  _mouseDown(event) {
    this._isDragging = true;
    this._startDrag.x = event.clientX;
    this._startDrag.y = event.clientY;
    // Save previous playback status and pause only if required
    if (this._player.paused === false) {
      this._wasPlaying = true;
      this._player.pause();
    }

    // Subscribe to drag events
    this._canvas.addEventListener('mousemove', this._mouseMove, false);
    this._canvas.addEventListener('mouseup', this._mouseUp, false);
    this._canvas.addEventListener('mouseout', this._mouseUp, false);
  }


  /** @method
   * @name _mouseDown
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Mouse move callback.</blockquote>
   * @param {object} event - The mouse move event **/
  _mouseMove(event) {
    // Only perform drag code if mouse down was previously fired
    if (this._isDragging === true) {
      const variation = (this._startDrag.x - event.clientX);
      const timeOffset = ((variation * this._canvasSpeed) / this._canvas.width) * 2;
      this._draggedTime = this._player.currentTime + timeOffset;
      this._clearCanvas();
      this._drawTimeline(this._draggedTime);
    }
  }


  /** @method
   * @name _mouseUp
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Mouse up callback.</blockquote> **/
  _mouseUp() {
    this._isDragging = false;
    this._startDrag.x = 0;
    this._startDrag.y = 0;
    this._player.currentTime = this._draggedTime || this._player.currentTime;
    this._draggedTime = null;
    // Restore playback status
    if (this._wasPlaying === true) {
      this._wasPlaying = false;
      this._player.play();
    }
    // Remove drag events
    this._canvas.removeEventListener('mousemove', this._mouseMove, false);
    this._canvas.removeEventListener('mouseup', this._mouseUp, false);
    this._canvas.removeEventListener('mouseout', this._mouseUp, false);
  }


  /** @method
   * @name _processAudioFile
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Perform an offline analysis on whole track.</blockquote>
   * @param {object} response - HTTP response for audio track to extract buffer from **/
  _processAudioFile(response) {
    // Set offline context according to track duration to get its full samples
    this._offlineCtx = new OfflineAudioContext(2, this._audioCtx.sampleRate * this._player.duration, this._audioCtx.sampleRate);
    this._offlineSource = this._offlineCtx.createBufferSource();
    this._audioCtx.decodeAudioData(response, buffer => {
      this._offlineSource.buffer = buffer;
      this._offlineSource.connect(this._offlineCtx.destination);
      this._offlineSource.start();
      this._offlineCtx.startRendering().then(renderedBuffer => {
        this._offlineBuffer = renderedBuffer;
        this._fillData();
        this._drawTimeline(this._player.currentTime || 0);
      }).catch(function(err) {
        console.log('Rendering failed: ' + err);
      });
    });
  }


  /** @method
   * @name _fillData
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Generate merged data from audio buffer.</blockquote> **/
  _fillData() {
    if (this._offlineBuffer) {
      // Clear any previous canvas
      this._canvases = [];
      this._cueCanvases = [];
      this._beatCanvases = [];
      // Compute useful values
      const data = this._genScaledMonoData(this._offlineBuffer);
      const step = (this._canvasSpeed * this._offlineBuffer.sampleRate) / this._canvas.width;
      const totalLength = Math.round((this._offlineBuffer.duration / this._canvasSpeed) * this._canvas.width);
      // Draw full track on offline canvas
      for (let i = 0; i < totalLength; i += MAX_CANVAS_WIDTH) {
        // Create canvas with width of the reduced-in-size buffer's length.
        const canvas = document.createElement('CANVAS');
        const ctx = canvas.getContext('2d');
        const cueCanvas = document.createElement('CANVAS');
        const beatCanvas = document.createElement('CANVAS');

        let width = totalLength - i;
        width = (width > MAX_CANVAS_WIDTH) ? MAX_CANVAS_WIDTH : width;
        // Update offline canvas dimension
        canvas.width = width;
        canvas.height = this._canvas.height;
        cueCanvas.width = width;
        cueCanvas.height = this._canvas.height;
        beatCanvas.width = width;
        beatCanvas.height = this._canvas.height;
        // Clear offline context
        ctx.clearRect(0, 0, totalLength, this._canvas.height);
        // Draw the canvas
        for (let j = 0; j < width; ++j) {
          const offset = Math.floor((i + j) * step);
          let max = 0.0; // The max value to draw
          // Update maximum value in step range
          for (let k = 0; k < step; ++k) {
            if (data[offset + k] > max) {
              max = data[offset + k];
            }
          }
          // Set waveform color according to sample intensity
          ctx.fillStyle = _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].lightenDarkenColor(this._colors.track, (max * 150)); // 150, not 255 to avoid full white on sample at max value
          // Update max to scale in half canvas height
          max = Math.floor(max * ((this._canvas.height * .9) / 2)); // Scale on 90% height max
          // Fill up and down side of timeline
          ctx.fillRect(j, this._canvas.height / 2, 1, -max);
          ctx.fillRect(j, this._canvas.height / 2, 1, +max);
          // Add tiny centered line
          ctx.fillRect(j, (this._canvas.height / 2) - 0.5, 1, 1);
        }
        // Store canvas to properly animate Timeline on progress
        this._canvases.push(canvas);
        this._cueCanvases.push(cueCanvas);
        this._beatCanvases.push(beatCanvas);
      }

      if (this._beat.bpm !== null && this._beat.offset !== null) {
        this._fillBeatBars({
          totalWidth: (this._offlineBuffer.duration / this._canvasSpeed) * this._canvas.width,
          beatWidth: ((1 / (this._beat.bpm / 60)) / this._canvasSpeed) * this._canvas.width,
          beatOffset: (this._beat.offset / this._canvasSpeed) * this._canvas.width
        });
      }
    }
  }


  _fillBeatBars(options) {
    let beatOffset = options.beatOffset;
    let canvasIndex = 0; // The offline canvas to consider
    // We floor because last beat is pretsty irrelevant
    for (let i = 0; i < Math.floor(options.totalWidth / options.beatWidth); ++i) {
      // We reached MAX_CANVAS_WIDTH, using next offline canvas
      if (i * options.beatWidth > MAX_CANVAS_WIDTH + (canvasIndex * MAX_CANVAS_WIDTH)) {
        // Increment offline canvas to use
        ++canvasIndex;
        // When changing canvas, the beatOffset is dependant to last beat saved position.
        beatOffset = options.beatWidth - (MAX_CANVAS_WIDTH - this._beats[this._beats.length - 1].yPos);
      }
      // Draw beat bar, x position is loop index times a space between beats, plus the beat offset,
      // modulo max canvas width to fit in offline canvases
      this._drawBeatBar(i, ((i * options.beatWidth) + beatOffset) % MAX_CANVAS_WIDTH, canvasIndex);
    }
  }


  /** @method
   * @name _drawBeatBar
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a beat bard with its triangle with color that depends on main beat or sub beat.</blockquote>
   * @param {object} beatCount - The beat number from first
   * @param {object} canvas - The canvas to draw in
   * @param {object} ctx - The associated context
   * @param {number} j - The y value **/
  _drawBeatBar(beatCount, x, canvasIndex) {
    const canvas = this._beatCanvases[canvasIndex];
    const ctx = canvas.getContext('2d');
    // Determine beat bar color
    if (beatCount % this._beat.timeSignature === 0) {
      ctx.fillStyle = 'white';
    } else {
      ctx.fillStyle = 'grey';
    }
    // Beat bar drawing
    ctx.fillRect(x, 9, 1, this._canvas.height - 18);
    // Determine beat triangle color
    if (beatCount % this._beat.timeSignature === 0) {
      ctx.fillStyle = this._colors.mainBeat;
    } else {
      ctx.fillStyle = this._colors.subBeat;
    }
    // Upper triangle
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawTriangle(canvas, {
      x: x,
      y: 4,
      radius: 6,
      top: 12
    });
    // Down triangle
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawTriangle(canvas, {
      x: x,
      y: this._canvas.height - 4,
      radius: 6,
      top: this._canvas.height - 12
    });
    // Update beats array with new beat bar
    this._beats.push({
      primaryBeat: (beatCount % this._beat.timeSignature === 0),
      beatCount: beatCount,
      yPos: x
    });
  }


  /** @method
   * @name _genScaledMonoData
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Merged L/R Sub sample channel data to compute average value, depending on bar count.</blockquote>
   * @param {object} buffer - Audio buffer
   * @return {number[]} Array of height per sub samples **/
  _genScaledMonoData(buffer) {
    const dataL = buffer.getChannelData(0);
    const dataR = buffer.getChannelData(1);
    const output = [];

    for (let i = 0; i < dataL.length; ++i) {
      output.push((Math.abs(dataL[i]) + Math.abs(dataR[i])) / 2);
    }

    return output;
  }


  /** @method
   * @name _drawTimeline
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw timeline with a given progress.</blockquote>
   * @param {number} time - Track current time **/
  _drawTimeline(time) {
    const center = Math.floor(time * this._canvas.width / this._canvasSpeed);
    let leftEdgeIndex = Math.floor((center - (this._canvas.width / 2)) / MAX_CANVAS_WIDTH);
    if (leftEdgeIndex < 0) {
      leftEdgeIndex = 0;
    }

    let rightEdgeIndex = Math.floor((center + (this._canvas.width / 2)) / MAX_CANVAS_WIDTH);
    if (rightEdgeIndex >= this._canvases.length) {
      rightEdgeIndex = this._canvases.length - 1;
    }

    for (let i = leftEdgeIndex; i <= rightEdgeIndex; ++i) {
      this._ctx.drawImage(this._canvases[i], (this._canvas.width / 2) - center + (MAX_CANVAS_WIDTH * i), 0);
      this._ctx.drawImage(this._cueCanvases[i], (this._canvas.width / 2) - center + (MAX_CANVAS_WIDTH * i), 0);
      this._ctx.drawImage(this._beatCanvases[i], (this._canvas.width / 2) - center + (MAX_CANVAS_WIDTH * i), 0);
    }
    // Draw centered vertical bar
    this._ctx.fillStyle = _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_2__["default"].defaultAntiPrimaryColor;
    this._ctx.fillRect(this._canvas.width / 2, 3, 3, this._canvas.height - 6);
    this._ctx.strokeStyle = 'black';
    this._ctx.lineWidth = 1;
    this._ctx.strokeRect(this._canvas.width / 2, 3, 3, this._canvas.height - 6);
  }


  /** @method
   * @name _getPlayerSourceFile
   * @private
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Fetch audio file using xmlHTTP request.</blockquote> **/
  _getPlayerSourceFile() {
    const request = new XMLHttpRequest();
    request.open('GET', this._player.src, true);
    request.responseType = 'arraybuffer';
    request.onload = () => { this._processAudioFile(request.response); };
    request.send();
  }


  _drawHotCue(hotcue) {
    _utils_CanvasUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].drawHotCue(this._cueCanvases[hotcue.canvasIndex], {
      x: hotcue.yPos - (hotcue.canvasIndex * MAX_CANVAS_WIDTH),
      y: 4,
      size: 18,
      label: hotcue.number
    });
  }


  _clearCueCanvas() {
    for (let i = 0; i < this._cueCanvases.length; ++i) {
      this._cueCanvases[i].getContext('2d').clearRect(0, 0, this._cueCanvases[i].width, this._cueCanvases[i].height);
    }
  }


  _fillCueCanvas() {
    for (let i = 0; i < this._hotCues.length; ++i) {
      this._drawHotCue(this._hotCues[i]);
    }
  }


  /*  --------------------------------------------------------------------------------------------------------------- */
  /*  ----------------------------------------  TIMELINE PUBLIC METHODS  -------------------------------------------  */
  /*                                                                                                                  */
  /*  These methods allow the caller to update the beat info (on change track for example), or to add/remove a hot    */
  /*  cue in the timeline.                                                                                            */
  /*  --------------------------------------------------------------------------------------------------------------- */


  /** @method
   * @name updateBeatInfo
   * @public
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Update the beat position.</blockquote>
   * @param {object} options - Track beat options
   * @param {number} [options.beat.offset=null] - offset before first beat
   * @param {number} [options.beat.bpm=null] - The track bpm
   * @param {number} [options.beat.timeSignature=null] - The track time signature to emphasis main beats **/
  updateBeatInfo(options) {
    this._beat = {
      offset: options.offset,
      bpm: options.bpm,
      timeSignature: options.timeSignature
    };
  }


  /** @method
   * @name setHotCuePoint
   * @public
   * @memberof Timeline
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Define a HotCue point. It will be attached to the nearest bar. It will only be
   * attached if no hotcue is registered on the targeted bar.</blockquote>
   * @return {object} The hotcue object with its information **/
  setHotCuePoint() {
    // The center coordinate when this method is called
    const center = Math.floor(this._player.currentTime * this._canvas.width / this._canvasSpeed);
    let matchingBeat = {};
    // Find nearest beat to process
    for (let i = 0; i < this._beats.length; ++i) {
      // We now have the upper beat, compare with previous one to find nearest
      if (this._beats[i].yPos > center) {
        // Take previous bar if click was closer to it
        if (i - 1 > 0 && (this._beats[i].yPos - center) > (center - this._beats[i - 1].yPos)) {
          matchingBeat = this._beats[i - 1];
          break;
        } else { // Take curent bar otherwise
          matchingBeat = this._beats[i];
          break;
        }
      }
    }
    // Save sub-canvas index in which the hot cue applies
    if (matchingBeat.yPos > MAX_CANVAS_WIDTH) {
      matchingBeat.canvasIndex = Math.floor(matchingBeat.yPos / MAX_CANVAS_WIDTH);
    } else {
      matchingBeat.canvasIndex = 0;
    }
    // Search for existing hotcue at the target bar
    let existing = false;
    for (let i = 0; i < this._hotCues.length; ++i) {
      if (this._hotCues[i].beatCount === matchingBeat.beatCount) {
        existing = true;
        break;
      }
    }
    // Only append hotcue if it's not already registered, return null otherwise
    if (!existing) {
      // Save hot cue and return to the sender
      matchingBeat.number = this._hotCues.length + 1; // Attach hotcue number
      matchingBeat.time = matchingBeat.yPos * this._canvasSpeed / this._canvas.width; // Save the bar timecode into the hotcue object
      this._hotCues.push(matchingBeat);
      // Draw hotcues if any
      this._drawHotCue(matchingBeat);
      this._drawTimeline(this._player.currentTime);
      return matchingBeat;
    } else {
      return null;
    }
  }


  removeHotCuePoint(hotcue) {
    for (let i = 0; i < this._hotCues.length; ++i) {
      if (this._hotCues[i].beatCount === hotcue.beatCount) {
        this._hotCues.splice(i, 1);
        this._clearCueCanvas();
        this._fillCueCanvas();
        this._drawTimeline(this._player.currentTime);
        break;
      }
    }
  }


}


/* harmony default export */ __webpack_exports__["default"] = (Timeline);


/***/ }),

/***/ "./src/js/components/WaveformProgress.js":
/*!***********************************************!*\
  !*** ./src/js/components/WaveformProgress.js ***!
  \***********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _utils_VisuComponentMono_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ../utils/VisuComponentMono.js */ "./src/js/utils/VisuComponentMono.js");
/* harmony import */ var _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ../utils/ColorUtils.js */ "./src/js/utils/ColorUtils.js");


'use strict';


class WaveformProgress extends _utils_VisuComponentMono_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary WaveformProgress displays the track audio waveform.
   * @author Arthur Beaulieu
   * @since 2020
   * @augments VisuComponentMono
   * @description <blockquote>This component will perform an offline analysis to display the whole track audio shape,
   * and provide different colors to track the audio progress. It is interactive and will update the player's
   * current time value to match the clicked one. This class extends VisuComponentMono only because it performs an offline
   * analysis on audio and the stereo information are already held in audio buffer.</blockquote>
   * @param {object} options - The waveform options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {object} [options.animation] - The track progress animation to be with <code>gradient</code> color
   * @param {object} [options.wave] - Wave potions
   * @param {string} [options.wave.align='center'] - Wave alignment in <code>top</code>/<code>center</code>/<code>bottom</code>
   * @param {number} [options.wave.barWidth=1] - The bar width in px
   * @param {number} [options.wave.barMarginScale=0.125] - The margin scale of bar width in Float[0,1]
   * @param {boolean} [options.wave.merged=true] - Symmetry if wave is align center
   * @param {object} [options.colors] - Waveform color potions
   * @param {object} [options.colors.background='#1D1E25'] - Canvas background color in Hex/RGB/HSL
   * @param {object} [options.colors.track='#E7E9E7'] - The waveform background color in Hex/RGB/HSL
   * @param {object} [options.colors.progress='#56D45B'] - The waveform progress color in Hex/RGB/HSL **/
  constructor(options) {
    super(options);

    this._colors = {
      background: options.colors ? options.colors.background || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].defaultBackgroundColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].defaultBackgroundColor,
      track: options.colors ? options.colors.track || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].defaultTextColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].defaultTextColor,
      progress: options.colors ? options.colors.progress || _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].defaultPrimaryColor : _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].defaultPrimaryColor
    };

    this._canvas.style.backgroundColor = this._colors.background;

    if (this._player.src !== '') {
      this._getPlayerSourceFile();
    }
  }


  /*  ----------  VisuComponentMono overrides  ----------  */



  /** @method
   * @name _fillAttributes
   * @private
   * @override
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Internal method to fill internal properties from options object sent to constructor.</blockquote>
   * @param {object} options - The frequency circle options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {object} [options.wave] - Waveform potions
   * @param {string} [options.wave.align='center'] - Waveform alignment in <code>top</code>/<code>center</code>/<code>bottom</code>
   * @param {number} [options.wave.barWidth=1] - The bar width in px
   * @param {number} [options.wave.barMarginScale=0] - The margin scale of bar width in Float[0,1]
   * @param {boolean} [options.wave.merged=true] - Symmetry if wave is aligned to center **/
  _fillAttributes(options) {
    super._fillAttributes(options);
      this._animation = options.animation;
    this._wave = {
      align: options.wave ? options.wave.align || 'center' : 'center',
      barWidth: options.wave ? options.wave.barWidth || 1 : 1,
      barMarginScale: options.wave ? (options.wave.barMarginScale / 2) : 0.125, // Divide by 2 because true range is [0, 0.5]
      merged: options.wave ? options.wave.merged || true : true
    };
    this._bars = null; // Computed on build or resize
    this._offlineCtx = null;
    this._offlineBuffer = null;
    // Raw channel data for whole audio file
    this._dataL = [];
    this._dataR = [];
    // Event binding
    this._trackLoaded = this._trackLoaded.bind(this);
    this._seekPlayer = this._seekPlayer.bind(this);
  }


  /** @method
   * @name _buildUI
   * @private
   * @override
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create and configure canvas then append it to given DOM element.</blockquote> **/
  _buildUI() {
    super._buildUI();
    this._bars = this._canvas.width / this._wave.barWidth;
  }


  /** @method
   * @name _addEvents
   * @private
   * @override
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Add component events (resize, play, pause, dbclick).</blockquote> **/
  _addEvents() {
    super._addEvents();
    this._player.addEventListener('loadedmetadata', this._trackLoaded, false);
    this._dom.container.addEventListener('click', this._seekPlayer, false);
  }


  /** @method
   * @name _removeEvents
   * @private
   * @override
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Remove component events (resize, play, pause, dbclick).</blockquote> **/
  _removeEvents() {
    super._removeEvents();
    this._player.removeEventListener('loadedmetadata', this._trackLoaded, false);
    this._dom.container.removeEventListener('click', this._seekPlayer, false);
  }


  /** @method
   * @name _onResize
   * @private
   * @override
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On resize event callback.</blockquote> **/
  _onResize() {
    super._onResize();
    this._bars = this._canvas.width / this._wave.barWidth;
    this._fillData();
    this._clearCanvas();
    this._drawFileWaveform(this._player.currentTime / this._player.duration);
  }


  /** @method
   * @name _dblClick
   * @private
   * @override
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On double click event callback.</blockquote> **/
  _dblClick() {
    // Required to revoke fullscreen toggle from parent class, as it interferes with seek feature
  }


  /** @method
   * @name _processAudioBin
   * @private
   * @override
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Real time method called by WebAudioAPI to process PCM data. Here we make a 8 bit frequency
   * and time analysis.</blockquote> **/
  _processAudioBin() {
    if (this._isPlaying === true) {
      this._clearCanvas();
      this._drawFileWaveform(this._player.currentTime / this._player.duration);
      requestAnimationFrame(this._processAudioBin);
    }
  }


  /*  ----------  Waveform internal methods  ----------  */


  /** @method
   * @name _trackLoaded
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Player callback on track loaded.</blockquote> **/
  _trackLoaded() {
    cancelAnimationFrame(this._processAudioBin);
    this._clearCanvas(); // Clear previous canvas
    // Do XHR to request file and parse it
    this._getPlayerSourceFile();
  }


  /** @method
   * @name _seekPlayer
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Update waveform progress according to mouse seek event.</blockquote>
   * @param {object} event - The mouse event **/
  _seekPlayer(event) {
    const boundingBox = event.target.getBoundingClientRect();
    const xOffset = event.clientX - boundingBox.left;
    this._player.currentTime = (xOffset / this._canvas.width) * this._player.duration;
    this._clearCanvas();
    this._drawFileWaveform(this._player.currentTime / this._player.duration);
  }


  /** @method
   * @name _processAudioFile
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Perform an offline analysis on whole track.</blockquote>
   * @param {object} response - HTTP response for audio track to extract buffer from **/
  _processAudioFile(response) {
    // Set offline context according to track duration to get its full samples
    this._offlineCtx = new OfflineAudioContext(2, this._audioCtx.sampleRate * this._player.duration, this._audioCtx.sampleRate);
    this._offlineSource = this._offlineCtx.createBufferSource();
    this._audioCtx.decodeAudioData(response, buffer => {
      this._offlineSource.buffer = buffer;
      this._offlineSource.connect(this._offlineCtx.destination);
      this._offlineSource.start();
      this._offlineCtx.startRendering().then(renderedBuffer => {
        this._offlineBuffer = renderedBuffer;
        this._fillData();
        this._drawFileWaveform(this._player.currentTime / this._player.duration);
      }).catch(function(err) {
        console.log('Rendering failed: ' + err);
      });
    });
  }


  /** @method
   * @name _fillData
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Generate merged or stereo data from audio buffer.</blockquote> **/
  _fillData() {
    if (this._offlineBuffer) {
      if (this._wave.merged === true) {
        // Mono output will only use L array to store L/R averages
        this._dataL = this._genScaledMonoData(this._offlineBuffer);
      } else {
        this._dataL = this._genScaledData(this._offlineBuffer.getChannelData(0));
        this._dataR = this._genScaledData(this._offlineBuffer.getChannelData(1));
      }
    }
  }


  /** @method
   * @name _genScaledData
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>L/R Sub sample channel data to compute average value, depending on bar count.</blockquote>
   * @param {Float32Array} data - Channel data (L/R here)
   * @return {number[]} Array of height per sub samples **/
  _genScaledData(data) {
    const subSampleSize = Math.floor(data.length / this._bars);
    const output = [];
    // We need to sub sample raw data according to the bar number. We average fq values
    for (let i = 0; i <= (data.length - subSampleSize); i += subSampleSize) {
      let sum = 0;
      for (let j = 0; j < subSampleSize; ++j) {
        sum += Math.abs(data[i + j]);
      }

      output.push(sum / subSampleSize);
    }

    return this._scaleDataToHeight(output);
  }


  /** @method
   * @name _genScaledMonoData
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Merged L/R Sub sample channel data to compute average value, depending on bar count.</blockquote>
   * @param {object} buffer - Audio buffer
   * @return {number[]} Array of height per sub samples **/
  _genScaledMonoData(buffer) {
    const dataL = buffer.getChannelData(0);
    const dataR = buffer.getChannelData(1);
    const subSampleSize = Math.floor(dataL.length / this._bars);
    const output = [];

    // We need to sub sample raw data according to the bar number. We average fq values
    for (let i = 0; i <= dataL.length - subSampleSize; i += subSampleSize) {
      let sum = 0;
      for (let j = 0; j < subSampleSize; ++j) {
        sum += (Math.abs(dataL[i + j]) + Math.abs(dataR[i + j])) / 2;
      }

      output.push(sum / subSampleSize);
    }

    return this._scaleDataToHeight(output);
  }


  /** @method
   * @name _scaleDataToHeight
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Scale channel data into an array of height to be used in canvas on draw.</blockquote>
   * @param {number[]} sampledData - Channel data
   * @return {number[]} Array of height per sub samples **/
  _scaleDataToHeight(sampledData) {
    // Convert a range to another, maintaining ratio
    // oldRange = (oldMax - oldMin)
    // newRange = (newMax - newMin)
    // newValue = (((oldValue - oldMin) * newRange) / oldRange) + NewMin */
    // We take max value of sampled data as 90% height in canvas as ref
    const oldMax = Math.max(...sampledData);
    const oldMin = Math.min(...sampledData);

    const oldRange = oldMax - oldMin;
    const newRange = this._canvas.height * .9;

    let scaledData = [];
    for (let i = 0; i < sampledData.length; ++i) {
      scaledData.push(((sampledData[i] - oldMin) * newRange) / oldRange);
    }

    return scaledData;
  }


  /** @method
   * @name _scaleDataToHeight
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw waveform with a given progress.</blockquote>
   * @param {number} progressPercentage - Track progress percentage **/
  _drawFileWaveform(progressPercentage) {
    const x = this._canvas.width / this._bars;
    const margin = x * this._wave.barMarginScale;

    this._ctx.beginPath();
    // Iterate bar data
    for (let i = 0; i < this._dataL.length; ++i) {
      // Determine Y pos for Up and Down rectangles to draw (in mono, we only use merged data in dataL array)
      const yU = this._dataL[i] / 2;
      const yD = (this._wave.merged === true) ? this._dataL[i] / 2 : this._dataR[i] / 2;
      // Determine bar color according to progress.
      this._ctx.fillStyle = this._colors.track; // White by default (un-read yet)
      if ((x * (i + 1)) / this._canvas.width > progressPercentage && (x * i) / this._canvas.width < progressPercentage) {
        // Create linear gradient on bar X dimension
        const gradient = this._ctx.createLinearGradient(
          x * i + margin, 0, // Bar X start
          x * (i + 1) - margin, 0 // Bar X end
        );
        // Get bar range in px
        let barRange = ((x * (i + 1))) - ((x * i));
        // We get progress X position according to canvas width
        let progressX = progressPercentage * this._canvas.width;
        // Convert this width into a percentage of barWidth progression
        let barProgressPercentage = (Math.abs(progressX - (x * i))) / (barRange);
        if (this._animation === 'gradient') {
          if (barProgressPercentage + 0.01 < 1) {
            gradient.addColorStop(0, this._colors.progress); // Green
            gradient.addColorStop(barProgressPercentage, this._colors.progress); // Green
            gradient.addColorStop(barProgressPercentage + 0.01, this._colors.track); // Not progressive gradient
            gradient.addColorStop(1, this._colors.track);
            this._ctx.fillStyle = gradient; // Gradient from green to white with correct progression in bar
          } else {
            this._ctx.fillStyle = this._colors.progress; // Green full for last position in bars
          }
        } else {
          const amount = Math.round(barProgressPercentage * 255);
          this._ctx.fillStyle = _utils_ColorUtils_js__WEBPACK_IMPORTED_MODULE_1__["default"].lightenDarkenColor(this._colors.progress, 255 - amount); // Green full for last position in bars
        }
     } else if (i / this._dataL.length < progressPercentage) {
        this._ctx.fillStyle = this._colors.progress; // Green for already played bars
      }
      // Draw up and down rectangles for current bar
      if (this._wave.align === 'center') {
        this._ctx.fillRect(x * i + margin, (this._canvas.height / 2) - yU, x - margin * 2, yU);
        this._ctx.fillRect(x * i + margin, this._canvas.height / 2, x - margin * 2, yD);
        // Add tiny centered line
        this._ctx.fillRect(x * i + margin, this._canvas.height / 2 - 0.15, x - margin * 2, 0.15);
      } else if (this._wave.align === 'bottom') {
        this._ctx.fillRect(x * i + margin, this._canvas.height - yU, x - margin * 2, yU);
        this._ctx.fillRect(x * i + margin, this._canvas.height - yU - yD + 1, x - margin * 2, yD); // Offset one pixel origin to blend channel properly
      } else if (this._wave.align === 'top') { // Stack L/R on each other
        this._ctx.fillRect(x * i + margin, 0, x - margin * 2, yU);
        this._ctx.fillRect(x * i + margin, yU - 1, x - margin * 2, yD); // Offset one pixel origin to blend channel properly
      }
    }

    this._ctx.closePath();
  }


  /** @method
   * @name _getPlayerSourceFile
   * @private
   * @memberof WaveformProgress
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Fetch audio file using xmlHTTP request.</blockquote> **/
  _getPlayerSourceFile() {
    const request = new XMLHttpRequest();
    request.open('GET', this._player.src, true);
    request.responseType = 'arraybuffer';
    request.onload = () => { this._processAudioFile(request.response); };
    request.send();
  }


}


/* harmony default export */ __webpack_exports__["default"] = (WaveformProgress);


/***/ }),

/***/ "./src/js/utils/BaseComponent.js":
/*!***************************************!*\
  !*** ./src/js/utils/BaseComponent.js ***!
  \***************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);



class BaseComponent {


  /** @summary BaseComponent is the bedrock of any visualisation here. It must be inherited from Mono or Stereo component abstraction.
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Store all base method, mostly to handle events, other processing methods needs to be overridden.</blockquote> **/
  constructor() {
    // Attributes that can be sent as options
    this._type = null;
    this._player = null; // Source (HTML audio player)
    this._renderTo = null; // Target div to render module in
    this._fftSize = null; // FFT size used to analyse audio stream
    // The Web Audio API context
    this._audioCtx = null;
    this._inputNode = null; // Optional, the source node to chain from ; it will ignore the output of HTML audio player
    // Display utils
    this._dom = {
      container: null
    };
    // Render to original dimension for fullscreen
    this._parentDimension = {
      position: null,
      height: null,
      width: null,
      zIndex: null
    };
    // Event binding
    this._resizeObserver = null;
    this._onResize = this._onResize.bind(this);
    this._play = this._play.bind(this);
    this._pause = this._pause.bind(this);
    this._dblClick = this._dblClick.bind(this);
    // Bind process audio bin for add and remove event on demand
    this._processAudioBin = this._processAudioBin.bind(this);
  }


  /** @method
   * @name destroy
   * @public
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>The destroy method to clear events and remove all component properties.</blockquote> **/
  destroy() {
    this._removeEvents();
    Object.keys(this).forEach(key => { delete this[key]; });
  }


  /** @method
   * @name _fillAttributes
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Build component properties from options. Must be implemented in sub class.</blockquote> **/
  _fillAttributes() {
    // Must be implemented in sub class
  }


  /** @method
   * @name _buildUI
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create, configure and append UI in DOM. Must be implemented in sub class.</blockquote> **/
  _buildUI() {
    // Must be implemented in sub class
  }


  /** @method
   * @name _setAudioNodes
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Build audio chain with source. Must be implemented in sub class.</blockquote> **/
  _setAudioNodes() {
    // Must be implemented in sub class
  }


  /** @method
   * @name _processAudioBin
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Real time audio analysis using PCM data from WebAudioAPI. Must be implemented in sub class.</blockquote> **/
  _processAudioBin() {
    // Must be implemented in sub class
  }


  /** @method
   * @name _addEvents
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Add component events (resize, play, pause, dbclick).</blockquote> **/
  _addEvents() {
    this._resizeObserver = new ResizeObserver(this._onResize);
    this._resizeObserver.observe(this._renderTo);
    this._player.addEventListener('play', this._play, false);
    this._player.addEventListener('pause', this._pause, false);
    this._dom.container.addEventListener('dblclick', this._dblClick, false);
  }


  /** @method
   * @name _removeEvents
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Remove component events (resize, play, pause, dbclick).</blockquote> **/
  _removeEvents() {
    this._resizeObserver.disconnect();
    this._player.removeEventListener('play', this._play, false);
    this._player.removeEventListener('pause', this._pause, false);
    this._dom.container.removeEventListener('dblclick', this._dblClick, false);
  }


  /** @method
   * @name _play
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On play event callback.</blockquote> **/
  _play() {
    this._isPlaying = true;
    this._processAudioBin();
  }


  /** @method
   * @name _pause
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On pause event callback.</blockquote> **/
  _pause() {
    this._isPlaying = false;
  }


  /** @method
   * @name _onResize
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On resize event callback. Must be implemented in sub class.</blockquote> **/
  _onResize() {
    // Resize must be handled in each sub class
  }


  /** @method
   * @name _dblClick
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On double click event callback (toggle fullscreen).</blockquote> **/
  _dblClick() {
    if (document.fullscreenElement) {
      document.exitFullscreen().then(() => {
        // Restore renderTo initial style
        this._renderTo.style.position = this._parentDimension.position;
        this._renderTo.style.height = this._parentDimension.height;
        this._renderTo.style.width = this._parentDimension.width;
        this._renderTo.style.zIndex = this._parentDimension.zIndex;
        this._parentDimension = {
          position: null,
          height: null,
          width: null,
          zIndex: null
        };
      });
    } else {
      document.documentElement.requestFullscreen().then(() => {
        // Update renderTo dimension (canvas will be automatically rescaled)
        this._parentDimension = {
          position: this._renderTo.style.position,
          height: this._renderTo.style.height,
          width: this._renderTo.style.width,
          zIndex: this._renderTo.style.zIndex || ''
        };
        this._renderTo.style.position = 'fixed';
        this._renderTo.style.height = '100vh';
        this._renderTo.style.width = '100vw';
        this._renderTo.style.zIndex = '999';
      });
    }
  }


  /** @method
   * @name _clearCanvas
   * @private
   * @memberof BaseComponent
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Clear component canvas contexts from their content. Must be implemented in sub class.</blockquote> **/
  _clearCanvas() {
    // Clear canvas must be handled in Mono/Stereo sub class depending on amount of canvas
  }


}


/* harmony default export */ __webpack_exports__["default"] = (BaseComponent);


/***/ }),

/***/ "./src/js/utils/CanvasUtils.js":
/*!*************************************!*\
  !*** ./src/js/utils/CanvasUtils.js ***!
  \*************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _ColorUtils_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ColorUtils.js */ "./src/js/utils/ColorUtils.js");

'use strict';


class CanvasUtils {


  /** @summary CanvasUtils provides several method to manipulate basic geometries in canvas
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>This class doesn't need to be instantiated, as all its methods are static in order to
   * make those utils methods available with constraints. Refer to each method for their associated documentation.</blockquote> */
  constructor() {}


  /** @method
   * @name drawRadialBar
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a radial bar with its height and color being computed from the frequency intensity.</blockquote>
   * @param {object} canvas - The canvas to draw radial bar in
   * @param {object} options - Radial bar options
   * @param {object} options.frequencyValue - The frequency value in Int[0,255]
   * @param {number} options.x0 - The x origin in canvas dimension
   * @param {number} options.y0 - The y origin in canvas dimension
   * @param {number} options.x1 - The x endpoint in canvas dimension
   * @param {number} options.y1 - The y endpoint in canvas dimension
   * @param {number} options.width - The bar line width in N
   * @param {string} options.color - The bar base color (will be lighten/darken according to frequency value) in Hex/RGB/HSL **/
  static drawRadialBar(canvas, options) {
    const ctx = canvas.getContext('2d');
    let amount = options.frequencyValue / 255;
    if (amount < 0.05) {
      amount = -amount;
    } else {
      amount = amount * 1.33;
    }
    // Draw on canvas context
    ctx.beginPath();
    ctx.moveTo(options.x0, options.y0);
    ctx.lineTo(options.x1, options.y1);
    ctx.strokeStyle = _ColorUtils_js__WEBPACK_IMPORTED_MODULE_0__["default"].lightenDarkenColor(options.color, amount * 100);
    ctx.lineWidth = options.width;
    ctx.stroke();
    ctx.closePath();
  }


  /** @method
   * @name drawCircle
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a circle in given canvas.</blockquote>
   * @param {object} canvas - The canvas to draw circle in
   * @param {object} options - Circle options
   * @param {number} options.centerX - The circle x origin in canvas dimension
   * @param {number} options.centerY - The circle y origin in canvas dimension
   * @param {number} options.radius - The circle radius
   * @param {number} options.radStart - The rotation start angle in rad
   * @param {number} options.radEnd - The rotation end angle in rad
   * @param {number} options.width - The circle line width in N
   * @param {string} options.color - The circle color in Hex/RGB/HSL **/
  static drawCircle(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();
    ctx.arc(options.centerX, options.centerY, options.radius, options.radStart, options.radEnd);
    ctx.lineWidth = options.width;
    ctx.strokeStyle = options.color;
    ctx.stroke();
    ctx.closePath();
  }


  /** @method
   * @name drawCircleGlow
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a circle with glow effect made with radial gradients in inner and outer circle.</blockquote>
   * @param {object} canvas - The canvas to draw circle glow in
   * @param {object} options - Circle glow options
   * @param {number} options.centerX - The circle x origin in canvas dimension
   * @param {number} options.centerY - The circle y origin in canvas dimension
   * @param {number} options.radius - The circle radius
   * @param {number} options.radStart - The rotation start angle in rad
   * @param {number} options.radEnd - The rotation end angle in rad
   * @param {number} options.width - The circle line width in N
   * @param {object[]} options.colors - the glow color, must be objects with color (in Hex/RGB/HSL) and index (in Float[0,1], 0.5 being the circle line) properties  **/
  static drawCircleGlow(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();
    ctx.arc(options.centerX, options.centerY, options.radius, options.radStart, options.radEnd);
    _ColorUtils_js__WEBPACK_IMPORTED_MODULE_0__["default"].drawRadialGlowGradient(canvas, options);
    ctx.closePath();
  }


  /** @method
   * @name drawDisc
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a disc in given canvas.</blockquote>
   * @param {object} canvas - The canvas to draw disc in
   * @param {object} options - Disc options
   * @param {number} options.centerX - The circle x origin in canvas dimension
   * @param {number} options.centerY - The circle y origin in canvas dimension
   * @param {number} options.radius - The circle radius
   * @param {number} options.radStart - The rotation start angle in rad
   * @param {number} options.radEnd - The rotation end angle in rad
   * @param {string} options.color - The circle color in Hex/RGB/HSL **/
  static drawDisc(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();
    ctx.arc(options.centerX, options.centerY, options.radius, options.radStart, options.radEnd);
    ctx.fillStyle = options.color;
    ctx.fill();
    ctx.closePath();
  }


  /** @method
   * @name drawVerticalBar
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a disc vertical bar in given canvas with given gradient.</blockquote>
   * @param {object} canvas - The canvas to draw disc in
   * @param {object} options - Vertical bar options
   * @param {number} options.originX - The x origin in canvas dimension
   * @param {number} options.height - The height of the frequency bin in canvas dimension
   * @param {number} options.width - The width of the frequency bin in canvas dimension
   * @param {object[]} options.colors - the gradient colors, must be objects with color and index (in Float[0,1]) properties **/
  static drawVerticalBar(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();
    ctx.fillRect(options.originX, canvas.height - options.height, options.width, options.height);
    _ColorUtils_js__WEBPACK_IMPORTED_MODULE_0__["default"].drawVerticalGradient(canvas, options);
    ctx.closePath();
  }


  /** @method
   * @name drawOscilloscope
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw an oscilloscope of frequencies in given canvas.</blockquote>
   * @param {object} canvas - The canvas to draw disc in
   * @param {object} options - Oscilloscope options
   * @param {number} options.samples - The x origin in canvas dimension
   * @param {number} options.timeDomain - The height of the frequency bin in canvas dimension
   * @param {string} options.color - the oscilloscope color in Hex/RGB/HSL or <code>rainbow</code> **/
  static drawOscilloscope(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();
    // Iterate over data to build each bar
    let cursorX = 0;
    const frequencyWidth = canvas.width / options.samples;
    for (let i = 0; i < options.samples; ++i) {
      // Compute frequency height percentage relative to canvas height to determine Y origin
      const frequencyHeight = options.timeDomain[i] / 255; // Get value between 0 and 1
      const cursorY = canvas.height * frequencyHeight;

      if (i > 0) { // General case
        ctx.lineTo(cursorX, cursorY);
      } else { // 0 index case
        ctx.moveTo(cursorX, cursorY);
      }
      // Update cursor position
      cursorX += frequencyWidth;
    }

    if (options.color === 'rainbow') {
      ctx.strokeStyle = _ColorUtils_js__WEBPACK_IMPORTED_MODULE_0__["default"].rainbowGradient(canvas);
    } else {
      ctx.strokeStyle = options.color;
    }

    ctx.stroke();
    ctx.closePath();
  }


  /** @method
   * @name drawPointsOscilloscope
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw an oscilloscope as points only in given canvas.</blockquote>
   * @param {object} canvas - The canvas to draw disc in
   * @param {object} options - Oscilloscope options
   * @param {number} options.length - the oscilloscope length (half FFT)
   * @param {number} options.times - The time domain bins
   * @param {string} options.color - The point color in Hex/RGB/HSL **/
  static drawPointsOscilloscope(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();

    for (let i = 0; i < options.length; ++i) {
      let height = canvas.height * (options.times[i] / 255);
      let offset = canvas.height - height - 1;
      let barWidth = canvas.width / options.length;
      ctx.fillStyle = options.color;
      ctx.fillRect(i * barWidth, offset, 2, 2);
    }

    ctx.stroke();
    ctx.fill();
    ctx.closePath();
  }


  /** @method
   * @name drawRadialOscilloscope
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a radial oscilloscope as points only in given canvas.</blockquote>
   * @param {object} canvas - The canvas to draw disc in
   * @param {object} options - Oscilloscope options
   * @param {number} options.centerX - the x center position
   * @param {number} options.centerY - the y center position
   * @param {number} options.rotation - the rotation offset
   * @param {number} options.length - the oscilloscope length (half FFT)
   * @param {number[]} options.times - The time domain bins
   * @param {number[]} options.points - The oscilloscope radial points objects
   * @param {string} options.color - The point color in Hex/RGB/HSL **/
  static drawRadialOscilloscope(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();
    ctx.save();
    ctx.translate(options.centerX, options.centerY);
    ctx.rotate(options.rotation)
    ctx.translate(-options.centerX, -options.centerY);
    ctx.moveTo(options.points[0].dx, options.points[0].dy);
    ctx.strokeStyle = options.color;

    for (let i = 0; i < options.length - 1; ++i) {
      let point = options.points[i];
      point.dx = point.x + options.times[i] * Math.sin((Math.PI / 180) * point.angle);
      point.dy = point.y + options.times[i] * Math.cos((Math.PI / 180) * point.angle);
      let xc = (point.dx + options.points[i + 1].dx) / 2;
      let yc = (point.dy + options.points[i + 1].dy) / 2;
      ctx.quadraticCurveTo(point.dx, point.dy, xc, yc);
    }
    // Handle last point manually
    let value = options.times[options.length - 1];
    let point = options.points[options.length - 1];
    point.dx = point.x + value * Math.sin((Math.PI / 180) * point.angle);
    point.dy = point.y + value * Math.cos((Math.PI / 180) * point.angle);
    let xc = (point.dx + options.points[0].dx) / 2;
    let yc = (point.dy + options.points[0].dy) / 2;
    ctx.quadraticCurveTo(point.dx, point.dy, xc, yc);
    ctx.quadraticCurveTo(xc, yc, options.points[0].dx, options.points[0].dy);
    // Fill context for current path
    ctx.lineWidth = 1;
    ctx.lineCap = 'round';
    ctx.stroke();
    ctx.restore();
    ctx.closePath();
  }


  /** @method
   * @name drawPeakMeter
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a peakmeter in given canvas.</blockquote>
   * @param {object} canvas - The canvas to draw disc in
   * @param {object} options - Peak meter options
   * @param {string} options.orientation - The peak meter orientation, either <code>horizontal</code> or <code>vertical</code>
   * @param {number} options.amplitude - The sample amplitude value
   * @param {number} options.peak - The peak value
   * @param {object[]} options.colors - The peak meter gradient colors, must be objects with color and index (in Float[0,1]) properties **/
  static drawPeakMeter(canvas, options) {
    const ctx = canvas.getContext('2d');
    _ColorUtils_js__WEBPACK_IMPORTED_MODULE_0__["default"].peakMeterGradient(canvas, options);

    if (options.orientation === 'horizontal') {
      const ledWidth = canvas.width - options.amplitude;
      ctx.fillRect(0, 0, ledWidth, canvas.height);
    } else if (options.orientation === 'vertical') {
      const ledHeight = canvas.height - options.amplitude;
      ctx.fillRect(0, canvas.height - ledHeight, canvas.width, ledHeight);
    }

    ctx.fillStyle = '#FF6B67';
    if (options.orientation === 'horizontal') {
      const ledWidth = canvas.width - options.peak;
      ctx.fillRect(ledWidth, 0, 1, canvas.height);
    } else if (options.orientation === 'vertical') {
      const ledHeight = canvas.height - options.peak;
      ctx.fillRect(0, canvas.height - ledHeight, canvas.width, 1);
    }
  }


  /** @method
   * @name drawTriangle
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a triangle in given canvas.</blockquote>
   * @param {object} canvas - The canvas to draw disc in
   * @param {object} options - Peak meter options
   * @param {number} options.x - The triangle x origin
   * @param {number} options.y - The triangle y origin
   * @param {number} options.radius - The triangle base
   * @param {number} options.top - The triangle top position **/
  static drawTriangle(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();
    ctx.moveTo(options.x - options.radius, options.y);
    ctx.lineTo(options.x + options.radius, options.y);
    ctx.lineTo(options.x, options.top);
    ctx.fill();
    ctx.closePath();
  }


  /** @method
   * @name drawSquare
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Draw a square in given canvas.</blockquote>
   * @param {object} canvas - The canvas to draw square in
   * @param {object} options - Peak meter options
   * @param {number} options.x - The square x origin
   * @param {number} options.y - The square y origin
   * @param {number} options.size - The square dimension **/
  static drawHotCue(canvas, options) {
    const ctx = canvas.getContext('2d');
    ctx.beginPath();
    ctx.fillStyle = _ColorUtils_js__WEBPACK_IMPORTED_MODULE_0__["default"].defaultPrimaryColor;    
    ctx.fillRect(options.x - (options.size / 2), options.y, options.size, options.size);
    ctx.fillStyle = _ColorUtils_js__WEBPACK_IMPORTED_MODULE_0__["default"].defaultBackgroundColor;
    ctx.font = 'bold 10pt Helvetica sans-serif';
    ctx.textAlign = 'center';
    ctx.fillText(options.label || '', options.x, options.y + (3 * options.size / 4));
    ctx.closePath();
  }  


  /** @method
   * @name precisionRound
   * @public
   * @memberof CanvasUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Round a floating number with a given precision after coma.</blockquote>
   * @param {number} value - The floating value to round
   * @param {number} precision - the amount of number we want to have after floating point
   * @return {number} - The rounded value **/
  static precisionRound(value, precision) {
    const multiplier = Math.pow(10, precision || 0);
    return Math.round(value * multiplier) / multiplier;
  }


}


/* harmony default export */ __webpack_exports__["default"] = (CanvasUtils);


/***/ }),

/***/ "./src/js/utils/ColorUtils.js":
/*!************************************!*\
  !*** ./src/js/utils/ColorUtils.js ***!
  \************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);



class ColorUtils {


  /** @summary ColorUtils provides several method to abstract color manipulation for canvas
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>This class doesn't need to be instantiated, as all its methods are static in order to
   * make those utils methods available without constraints. Refer to each method for their associated documentation.</blockquote> */
  constructor() {}


  /** @method
   * @name drawRadialGradient
   * @public
   * @memberof ColorUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Fill context with radial gradient according to options object.</blockquote>
   * @param {object} canvas - The canvas to draw radial gradient in
   * @param {object} options - Radial gradient options
   * @param {number} options.x0 - The x origin in canvas dimension
   * @param {number} options.y0 - The y origin in canvas dimension
   * @param {number} options.r0 - The radius of the start circle in Float[0,2PI]
   * @param {number} options.x1 - The x endpoint in canvas dimension
   * @param {number} options.y1 - The y endpoint in canvas dimension
   * @param {number} options.r1 - The radius of the end circle in Float[0,2PI]
   * @param {object[]} options.colors - The color gradient, must be objects with color (in Hex/RGB/HSL) and index (in Float[0,1]) properties **/
  static drawRadialGradient(canvas, options) {
    const ctx = canvas.getContext('2d');
    const gradient = ctx.createRadialGradient(
      options.x0, options.y0, options.r0,
      options.x1, options.y1, options.r1
    );

    for (let i = 0; i < options.colors.length; ++i) {
      gradient.addColorStop(options.colors[i].index, options.colors[i].color);
    }

    ctx.fillStyle = gradient;
    ctx.fillRect(0, 0, canvas.width, canvas.height);
  }


  /** @method
   * @name drawVerticalGradient
   * @public
   * @memberof ColorUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Fill context with vertical gradient according to options object.</blockquote>
   * @param {object} canvas - The canvas to draw vertical gradient in
   * @param {object} options - Vertical gradient options
   * @param {number} options.originX - The bar x origin in canvas dimension
   * @param {number} options.height - The bar height in canvas dimension
   * @param {number} options.width - The bar width in canvas dimension
   * @param {object[]} options.colors - The color gradient, must be objects with color (in Hex/RGB/HSL) and index (in Float[0,1]) properties **/
  static drawVerticalGradient(canvas, options) {
    const ctx = canvas.getContext('2d');
    const gradient = ctx.createLinearGradient(
      0, canvas.height,
      0, 0
    );

    for (let i = 0; i < options.colors.length; ++i) {
      gradient.addColorStop(options.colors[i].index, options.colors[i].color);
    }

    ctx.fillStyle = gradient;
    ctx.fillRect(options.originX, canvas.height - options.height, options.width, options.height);
  }


  /** @method
   * @name drawRadialGlowGradient
   * @public
   * @memberof ColorUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Fill context with radial glowing gradient according to options object.</blockquote>
   * @param {object} canvas - The canvas to draw radial glowing gradient in
   * @param {object} options - Radial glowing gradient options
   * @param {number} options.centerX - The center x origin in canvas dimension
   * @param {number} options.centerY - The center y origin in canvas dimension
   * @param {number} options.radius - The circle radius in canvas dimension
   * @param {object[]} options.colors - The color gradient, must be objects with color (in Hex/RGB/HSL) and index (in Float[0,1]) properties **/
  static drawRadialGlowGradient(canvas, options) {
    const ctx = canvas.getContext('2d');
    const gradient = ctx.createRadialGradient(
      options.centerX, options.centerY, 0,
      options.centerX, options.centerY, options.radius
    );

    for (let i = 0; i < options.colors.length; ++i) {
      gradient.addColorStop(options.colors[i].index, options.colors[i].color);
    }

    ctx.fillStyle = gradient;
    ctx.fill();
  }


  /** @method
   * @name peakMeterGradient
   * @public
   * @memberof ColorUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Fill peakmeter context with audio gradient according to options.</blockquote>
   * @param {object} canvas - The canvas to draw radial glowing gradient in
   * @param {object} options - Radial glowing gradient options
   * @param {string} options.orientation - The peak meter orientation (<code>vertical</code> or <code>horizontal</code>)
   * @param {object[]} options.colors - The color gradient, must be objects with color (in Hex/RGB/HSL) and index (in Float[0,1]) properties **/
  static peakMeterGradient(canvas, options) {
    const ctx = canvas.getContext('2d');
    let gradient = null;

    if (options.orientation === 'horizontal') {
      gradient = ctx.createLinearGradient(0, 0, canvas.width, 0);
    } else if (options.orientation === 'vertical') {
      gradient = ctx.createLinearGradient(0, canvas.height, 0, 0);
    } else {
      return;
    }

    for (let i = 0; i < options.colors.length; ++i) {
      gradient.addColorStop(options.colors[i].center, options.colors[i].color);
    }

    ctx.fillStyle = gradient;
    ctx.fill();
  }


  /** @method
   * @name lightenDarkenColor
   * @public
   * @memberof ColorUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Lighten or darken a given color from an amount. Inspired from https://jsfiddle.net/gabrieleromanato/hrJ4X/</blockquote>
   * @param {string} color - The color to alter in Hex/RGB/HSL
   * @param {number} amount - The percentage amount to lighten or darken in Float[-100,100]
   * @return {string} The altered color in Hex/RGB/HSL **/
  static lightenDarkenColor(color, amount) {
    let usePound = false;
    if (color[0] === '#') {
      color = color.slice(1);
      usePound = true;
    }

    amount += 16;
    const num = parseInt(color, 16);
    // Red channel bounding
    let r = (num >> 16) + amount;
    if (r > 255) {
      r = 255;
    } else if (r < 0) {
      r = 0;
    }
    // Blue channel bounding
    let b = ((num >> 8) & 0x00FF) + amount;
    if (b > 255) {
      b = 255;
    } else if (b < 0) {
      b = 0;
    }
    // Green channel bounding
    let g = (num & 0x0000FF) + amount;
    if (g > 255) {
      g = 255;
    } else if (g < 0) {
      g = 0;
    }

    return (usePound ? '#' : '') + (g | (b << 8) | (r << 16)).toString(16);
  }


  /** @method
   * @name rainbowGradient
   * @public
   * @memberof ColorUtils
   * @static
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Return a vertical or horizontal rainbow gradient.</blockquote>
   * @param {object} canvas - The canvas to create gradient from
   * @param {boolean} [vertical=false] - The gradient orientation, default to horizontal
   * @return {object} The rainbow gradient to apply **/
  static rainbowGradient(canvas, vertical = false) {
    const ctx = canvas.getContext("2d");
    let gradient = ctx.createLinearGradient(0, 0, canvas.width, 0);
    if (vertical === true) {
      gradient = ctx.createLinearGradient(0, 0, 0, canvas.height);
    }
    gradient.addColorStop(0, 'red');
    gradient.addColorStop(1 / 7, 'orange');
    gradient.addColorStop(2 / 7, 'yellow');
    gradient.addColorStop(3 / 7, 'green');
    gradient.addColorStop(4 / 7, 'blue');
    gradient.addColorStop(5 / 7, 'indigo');
    gradient.addColorStop(6 / 7, 'violet');
    gradient.addColorStop(1, 'red');
    return gradient;
  }


  /** @public
   * @static
   * @member {string} - The default background color, #1D1E25 */
  static get defaultBackgroundColor() {
    return '#1D1E25';
  }


  /** @public
   * @static
   * @member {string} - The default text color, #E7E9E7 */
  static get defaultTextColor() {
    return '#E7E9E7';
  }


  /** @public
   * @static
   * @member {string} - The default primary color, #56D45B */
  static get defaultPrimaryColor() {
    return '#56D45B';
  }


  /** @public
   * @static
   * @member {string} - The default anti primary color, #FF6B67 */
  static get defaultAntiPrimaryColor() {
    return '#FF6B67';
  }


  /** @public
   * @static
   * @member {string} - The default dark primary color, #12B31D */
  static get defaultDarkPrimaryColor() {
    return '#12B31D';
  }


  /** @public
   * @static
   * @member {string[]} - The default color array to be used in gradient, <code>['#56D45B', '#AFF2B3', '#FFAD67', '#FF6B67', '#FFBAB8']</code> */
  static get defaultAudioGradient() {
    // Green, Light Green, Orange, Red, Light Red
    return ['#56D45B', '#AFF2B3', '#FFAD67', '#FF6B67', '#FFBAB8'];
  }


}


/* harmony default export */ __webpack_exports__["default"] = (ColorUtils);


/***/ }),

/***/ "./src/js/utils/VisuComponentMono.js":
/*!*******************************************!*\
  !*** ./src/js/utils/VisuComponentMono.js ***!
  \*******************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _BaseComponent_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BaseComponent.js */ "./src/js/utils/BaseComponent.js");

'use strict';


class VisuComponentMono extends _BaseComponent_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary VisuComponentMono is an abstraction for mono visualisation component. It must be inherited.
   * @author Arthur Beaulieu
   * @since 2020
   * @augments BaseComponent
   * @description <blockquote>Mono components inherit this class to benefit its node routing and canvas
   * configuration. It is meant to use a single canvas for mono or merged L/R audio channels. This class extends
   * BaseComponent to benefits all shared properties between visualisations.</blockquote>
   * @param {object} options - The visualizer root options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one **/
  constructor(options) {
    super();
    // Audio nodes
    this._nodes = {
      source: null, // HTML audio element
      analyser: null // Analysis node
    };
    this._isPlaying = false;
    // Canvas and context
    this._canvas = null;
    this._ctx = null;
    // Construction sequence
    this._fillAttributes(options);
    this._buildUI();
    this._setAudioNodes();
    this._addEvents();
  }


  /** @method
   * @name _fillAttributes
   * @private
   * @override
   * @memberof VisuComponentMono
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Internal method to fill internal properties from options object sent to constructor.</blockquote>
   * @param {object} options - The visualizer root options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one **/
  _fillAttributes(options) {
    this._type = options.type;
    this._player = options.player;
    this._renderTo = options.renderTo;
    this._fftSize = options.fftSize;
    this._audioCtx = options.audioContext;
    this._inputNode = options.inputNode;
  }


  /** @method
   * @name _buildUI
   * @private
   * @override
   * @memberof VisuComponentMono
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create and configure canvas then append it to given DOM element.</blockquote> **/
  _buildUI() {
    this._dom.container = document.createElement('DIV');
    this._dom.container.classList.add(`audio-${this._type}`);
    this._canvas = document.createElement('CANVAS');
    this._canvas.style.cssText = 'background-color:black;border:solid 1px #2c2c30;display:block;box-sizing:border-box;';
    this._ctx = this._canvas.getContext('2d');
    this._ctx.translate(0.5, 0.5);
    this._canvas.width = this._renderTo.offsetWidth - 2;
    this._canvas.height = this._renderTo.offsetHeight - 2;
    this._dom.container.appendChild(this._canvas);
    this._renderTo.appendChild(this._dom.container);
  }


  /** @method
   * @name _setAudioNodes
   * @private
   * @override
   * @memberof VisuComponentMono
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Build audio chain with source -> analyzer -> destination.</blockquote> **/
  _setAudioNodes() {
    let audioCtxSent = false;
    if (!this._audioCtx) {
      this._audioCtx = new AudioContext();
      this._nodes.source = this._audioCtx.createMediaElementSource(this._player);
    } else {
      audioCtxSent = true;
      this._nodes.source = this._inputNode;
    }

    this._nodes.analyser = this._audioCtx.createAnalyser();
    this._nodes.analyser.fftSize = this._fftSize;

    this._nodes.source.connect(this._nodes.analyser);

    if (!audioCtxSent) {
      this._nodes.analyser.connect(this._audioCtx.destination);
    }
  }


  /** @method
   * @name _onResize
   * @private
   * @override
   * @memberof VisuComponentMono
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>On resize event callback.</blockquote> **/
  _onResize() {
    this._canvas.width = this._renderTo.offsetWidth - 2;
    this._canvas.height = this._renderTo.offsetHeight - 2;
  }


  /** @method
   * @name _clearCanvas
   * @private
   * @override
   * @memberof VisuComponentMono
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Clear component canvas context from its content.</blockquote> **/
  _clearCanvas() {
    this._canvas.getContext('2d').clearRect(0, 0, this._canvas.width, this._canvas.height);
  }


}


/* harmony default export */ __webpack_exports__["default"] = (VisuComponentMono);


/***/ }),

/***/ "./src/js/utils/VisuComponentStereo.js":
/*!*********************************************!*\
  !*** ./src/js/utils/VisuComponentStereo.js ***!
  \*********************************************/
/*! exports provided: default */
/***/ (function(module, __webpack_exports__, __webpack_require__) {

"use strict";
__webpack_require__.r(__webpack_exports__);
/* harmony import */ var _BaseComponent_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./BaseComponent.js */ "./src/js/utils/BaseComponent.js");

'use strict';


class VisuComponentStereo extends _BaseComponent_js__WEBPACK_IMPORTED_MODULE_0__["default"] {


  /** @summary VisuComponentStereo is an abstraction for stereo visualisation components. It must be inherited.
   * @author Arthur Beaulieu
   * @since 2020
   * @augments BaseComponent
   * @description <blockquote>Stereo components inherit this class to benefit its node routing and canvas
   * configuration. It is meant to use a L/R canvas for stereo or merged L/R one. This class extends BaseComponent to
   * benefits all shared properties between visualisations.</blockquote>
   * @param {object} options - The visualizer root options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {boolean} [options.merged=false] - Merge channels into mono output **/
  constructor(options) {
    super();
    // Merge L and R channel on output
    this._merged = null;
    // Audio nodes
    this._nodes = {
      source: null, // HTML audio element
      splitter: null, // Stereo channel splitting
      merger: null, // Merge channels into one
      analyser: null, // Merged stereo channels analysis
      analyserL: null, // Left channel analysis
      analyserR: null // Right channel analysis
    };
    // Canvas and context
    this._canvasL = null;
    this._canvasR = null;
    this._ctxL = null;
    this._ctxR = null;
    // Construction sequence
    this._fillAttributes(options);
    this._buildUI();
    this._setAudioNodes();
    this._addEvents();
  }


  /** @method
   * @name _fillAttributes
   * @private
   * @override
   * @memberof VisuComponentStereo
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Internal method to fill internal properties from options object sent to constructor.</blockquote>
   * @param {object} options - The visualizer root options
   * @param {string} options.type - The component type as string
   * @param {object} options.player - The player to take as processing input (if inputNode is given, player source will be ignored)
   * @param {object} options.renderTo - The DOM element to render canvas in
   * @param {number} options.fftSize - The FFT size for analysis. Must be a power of 2. High values may lead to heavy CPU cost
   * @param {object} [options.audioContext=null] - The audio context to base analysis from
   * @param {object} [options.inputNode=null] - The audio node to take source instead of player's one
   * @param {boolean} [options.merged=false] - Merge channels into mono output **/
  _fillAttributes(options) {
    this._type = options.type;
    this._player = options.player;
    this._renderTo = options.renderTo;
    this._fftSize = options.fftSize || 1024;
    this._audioCtx = options.audioContext;
    this._inputNode = options.inputNode;
    this._merged = options.merged || false;
  }


  /** @method
   * @name _buildUI
   * @private
   * @override
   * @memberof VisuComponentStereo
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Create and configure canvas then append it to given DOM element.</blockquote> **/
  _buildUI() {
    this._dom.container = document.createElement('DIV');
    this._dom.container.classList.add(`audio-${this._type}`);
    this._canvasL = document.createElement('canvas');
    this._canvasR = document.createElement('canvas');
    this._canvasL.style.cssText = 'background-color:black;border: solid 1px #2c2c30;display:block;box-sizing:border-box;';
    this._canvasR.style.cssText = 'background-color:black;border: solid 1px #2c2c30;display:block;box-sizing:border-box;';
    this._ctxL = this._canvasL.getContext('2d');
    this._ctxR = this._canvasR.getContext('2d');
    this._ctxL.translate(0.5, 0.5);
    this._ctxR.translate(0.5, 0.5);
    this._dom.container.appendChild(this._canvasL);
    this._dom.container.appendChild(this._canvasR);
    this._renderTo.appendChild(this._dom.container);
  }


  /** @method
   * @name _setAudioNodes
   * @private
   * @override
   * @memberof VisuComponentStereo
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Build audio chain with source -> splitter -> analyzerL/R -> merger -> destination.</blockquote> **/
  _setAudioNodes() {
    let audioCtxSent = false;
    if (!this._audioCtx) {
      this._audioCtx = new AudioContext();
      this._nodes.source = this._audioCtx.createMediaElementSource(this._player);
    } else {
      audioCtxSent = true;
      this._nodes.source = this._inputNode;
    }

    let outputNode;
    if (this._merged === true) {
      this._nodes.analyser = this._audioCtx.createAnalyser();
      this._nodes.analyser.fftSize = this._fftSize;
      // Nodes chaining
      this._nodes.source.connect(this._nodes.analyser);
      outputNode = this._nodes.analyser;
    } else {
      this._nodes.splitter = this._audioCtx.createChannelSplitter(this._nodes.source.channelCount);
      this._nodes.merger = this._audioCtx.createChannelMerger(this._nodes.source.channelCount);
      this._nodes.analyserL = this._audioCtx.createAnalyser();
      this._nodes.analyserR = this._audioCtx.createAnalyser();
      this._nodes.analyserR.fftSize = this._fftSize;
      this._nodes.analyserL.fftSize = this._fftSize;
      // Nodes chaining
      this._nodes.source.connect(this._nodes.splitter);
      this._nodes.splitter.connect(this._nodes.analyserL, 0);
      this._nodes.splitter.connect(this._nodes.analyserR, 1);
      this._nodes.analyserL.connect(this._nodes.merger, 0, 0);
      this._nodes.analyserR.connect(this._nodes.merger, 0, 1);
      outputNode = this._nodes.merger;
    }

    if (!audioCtxSent) {
      outputNode.connect(this._audioCtx.destination);
    } else {
      // If any previous context exists, we mute this channel to not disturb any playback
      const gainNode = this._audioCtx.createGain();
      gainNode.gain.value = 0;
      outputNode.connect(gainNode);
      gainNode.connect(this._audioCtx.destination);
    }
  }


  /** @method
   * @name _clearCanvas
   * @private
   * @override
   * @memberof VisuComponentStereo
   * @author Arthur Beaulieu
   * @since 2020
   * @description <blockquote>Clear component canvas contexts from their content.</blockquote> **/
  _clearCanvas() {
    this._canvasL.getContext('2d').clearRect(0, 0, this._canvasL.width, this._canvasL.height);
    this._canvasR.getContext('2d').clearRect(0, 0, this._canvasR.width, this._canvasR.height);
  }


}


/* harmony default export */ __webpack_exports__["default"] = (VisuComponentStereo);


/***/ }),

/***/ "./src/scss/audiovisualizer.scss":
/*!***************************************!*\
  !*** ./src/scss/audiovisualizer.scss ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

// extracted by mini-css-extract-plugin

/***/ }),

/***/ 0:
/*!*************************************************************************!*\
  !*** multi ./src/js/AudioVisualizer.js ./src/scss/audiovisualizer.scss ***!
  \*************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

__webpack_require__(/*! ./src/js/AudioVisualizer.js */"./src/js/AudioVisualizer.js");
module.exports = __webpack_require__(/*! ./src/scss/audiovisualizer.scss */"./src/scss/audiovisualizer.scss");


/***/ })

/******/ });